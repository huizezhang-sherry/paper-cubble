---
documentclass: jss
author:
  - name: H. Sherry Zhang
    # department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    #location: Melbourne, Australia
    email: \email{huize.zhang@monash.edu}
  - name: Dianne Cook
    # department: Department of Econometrics and Business Statistics
    affiliation: 'Monash University \AND'
    # location: Melbourne, Australia
    # email:  dicook@monash.edu
  - name: Ursula Laa
    # department: Institute of Statistics
    affiliation: 'University of Natural Resources and Life Sciences \AND'
    # location: Vienna, Austria
    # email:  ursula.laa@boku.ac.at
  - name: Nicolas Langrené
    # department: 34 Village Street, Docklands VIC 3008 Australia
    affiliation: 'CSIRO Data61 \AND'
    # location: Melbourne, Australia
    # email: nicolas.langrene@csiro.au
  - name: Patricia Menéndez
    # department: Department of Econometrics and Business Statistics
    affiliation: 'Monash University \AND'
    # location: Melbourne, Australia
    # email:  patricia.menendez@monash.edu
title:
  formatted: "\\pkg{cubble}: An R Package for Structuring Spatio-temporal Data"
  # If you use tex in the formatted title, alsoge supply version without
  plain:     "cubble: An R Package for Structuring Spatio-temporal Data"
  # For running headers, if needed
  # short:     "\\pkg{foo}: A Capitalized Title"
abstract: >
  The abstract of the article.
keywords:
  # at least one keyword must be supplied
  formatted: [spatio-temporal data,  "\\proglang{R}"]
  plain:     [spatio-temporal data, R]
preamble: >
  \usepackage{amsmath}
  \usepackage{array}
output: rticles::jss_article
bibliography: references.bib
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  cache = TRUE,
  fig.path = "figures/",
  fig.height = 10
)
options(prompt = "R> ", continue = "+ ")
```

```{r echo = FALSE}
library(cubble)
library(forcats)
library(stringr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(GGally)
library(plotly)
library(crosstalk)
library(patchwork)
```

\newpage

# Introduction

**Motivation**

Many data structures have been proposed for spatial (\pkg{sf} by @sf) and temporal (\pkg{tsibble} by @tsibble) data in the R community, while less has been done for spatio-temporal data. The lack of such tools could potentially because analysts usually treat the spatial and temporal dimension of the data separately, without realising the need to create a new data structure. While this approach follows the third tidy data principal [@tidydata] (*Each type of observational unit forms a table*), analysts always need to manually join results from different observational units or combining multiple tables into one for downstream analysis. This additional step doesn't add new operations into the data but can be error prone. \newline

**Existing packages**

Currently, available spatio-temporal data structure in R includes: \pkg{spacetime} [@spacetime], which proposes four space-time layouts: Full grid (STF), sparse grid(STS), irregular (STI), and trajectory (STT). The data structure it uses is based on \pkg{sp} [@sp] and \pkg{xts} [@xts], both of which has been replaced by more recent implementations. \pkg{spatstat} [@spatstat] implements a `ppp` class for point pattern data; and more recent, \pkg{stars} [@stars] implements a spatio-temporal array with the dplyr's data cube structure \pkg{cubelyr} [@cubelyr] as its backend. While these implementations either store spatial and temporal variables all in a single table, hence duplicate the spatial variables for each temporal unit; or split them into two separate tables that has the problem of manually joining, mentioned in the previously. None of these packages enjoy both the benefits of being able to separate manipulation in the two dimensions while also keep the data object as a whole. This create a gap in the software development. The requirement for such a tool is important given the ubiquity of spatio-temporal vector data in the wild: the Ireland wind data from \pkg{gstat} is an classic example data that splits variables into spatial (`wind.loc`) and temporal (`wind`) dimension; Bureau of Meteorology (BoM) provides climate observations that are widely applied in agriculture and ecology study; air pollution data. \newline

**Our new data structure for spatio-temporal data**
This paper describes the implementation of a new spatio-temporal data structure: \pkg{cubble}. \pkg{cubble} implements a relational data structure that uses two forms to manage the switch between spatial and temporal dimension. With this structure, users can manipulate the spatial or temporal dimension separately, while leaves the linking of two dimensions to \pkg{cubble\pkg{. The software is available from the Comprehensive R Archive Network (CRAN) at [CRAN link]. \newline

**Section division**

The rest of the paper will be divided as follows: [complete when the paper structure is more solid]

<!-- Section 2 reviews the existing data structure for spatio, temporal, and spatio-temporal data. Section 3 presents a new data structure for spatio-temporal data: cubble. Then the paper introduces the workflow of data manipulation and visualisation with the cubble structure in Section 4. Section 5 gives some examples on how common spatial and temporal manipulations are performed with cubble and how static and interactive visualisation help to understand climate and [...] data. \newline -->

\newpage

# The cubble package

Spatio-temporal data usually come in various forms and Figure \ref{fig:cubble-diagram} shows four examples of this. No matter which form the data is in, these formats share some common components that characterise spatio-temporal data. A spatial identifier (`id` in the diagram) is the unique identifier of each site. The temporal identifier (`t` in the diagram) prescribes the time stamp each site is recorded. Coordinates, comprising of latitude and longitude (`lon` and `lat` in the diagram), locates each site on the map. These identifiers will be the building blocks for the data structure introduced below. Other variables in the data can be categorised into two groups: spatial variables that are invariant at each time stamp for every site, i.e. the name or code of the weather station and temporal variables that varies with time.

```{r cubble-diagram, echo = FALSE, out.width = "100%", fig.cap="Illustration of incoming data formats for spatio-temporal data. (1) Data comes in as a single table; (2) Separate tables for spatial and temporal variables; (3) A single table with all the parameters used to query the database and a separate table for queried data; and (4) Cubical data in array or NetCDF format.", fig.align='center', out.height = "15%"}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.001.png"))
```

In a cubble, there are two forms: nested form and long form, and Figure \ref{fig:def-cubble} sketches the two forms along with the associated attributes. The decision on which form to use is output-oriented, meaning analysts need to first think about whether the output of a particular operation is identified only by the spatial identifier, or a combination of spatial and temporal identifier. The nested cubble is suitable for working with operations that are only identified by site and this type of operation can be a pure manipulation of spatial variables, or a summary of temporal variables by site (i.e. the output of counting the number of raining day is only identified by sites and hence should be performed with the nested form). Underneath the nested form, a cubble is built from a row-wise dataframe (`rowwise_df`) where each site forms a separate group. This structure simplifies the calculation that involves temporal variables by avoiding the use of `map` syntax when working with list-column.

For those operations whose output involves both a spatial and temporal dimension, long form should be used. The long form is identified by both the spatial and temporal identifier and adopts a grouped dataframe (`grouped_df`) to forms each site as a group. Spatial variables are stored separately in a \pkg{tibble} as an special attribute of the long cubble. This design avoids repeating the spatial variables at each time stamp while not dropping information from spatial variables.

```{r def-cubble, echo = FALSE, fig.align="center", out.width = "100%", fig.cap = "Illustration of nested and long cubble."}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.002.png"))
```

## Create a cubble in the nested form

To use functionalities from cubble, data analysts first need to create a cubble. `as_cubble` create a \pkg{cubble} by supplying the three key components: `key` as the spatial identifier; `index` as the temporal identifier; and a vector of `coords` in the order of longitude first and then latitude. The naming of `key` and `index` follows the convention in the \pkg{tsibble} package. The cubble created by default is in the nested form. Below is an example of creating a cubble: \newline

```{r}
(cubble_nested <- cubble::climate_flat %>%
  as_cubble(key = id, index = date, coords = c("long", "lat")))
```

There are a few information in the \pkg{cubble} header: the name of the `key` variable, bbox, and also the name of variable nested in the `ts` column. In this example, each site is identifier is `id` and the number in the bracket means there are 5 unique `id` in this dataset. The bbox in the second row gives the range of the coordinates. The temporal variables are all nested in the `ts` column, but it could be useful to know the name these variables. The third row in the cubble header shows these names and in this example this includes: precipitation, `prcp`, maximum temperature, `tmax`, and minimum temperature, `tmin`.

## Stretch a nested cubble into the long form

The long cubble is suitable to manipulate the time dimension of the data. The function `stretch()` switches the nested cubble into the long cubble by first extracts all the spatial variables into a separate tibble and store in the `spatial` attribute and then unnests the `ts` column:

```{r}
(cubble_long <- cubble_nested %>% stretch(ts))
```

Notice here that the third line in the header now shows the name of spatial variables rather than the temporal variables.

## Tamp a long cubble back to the nested form

Manipulation on the spatial and temporal dimension can be an iterative process. Many times, analysts will need to go back and forth between the nested and long cubble. The `stretch()` function introduced in the previous section switches a nested cubble into a long cubble and function `tamp()` is its inverse function to switch a long cubble back to the nested cubble:

```{r}
(cubble_back <- cubble_long %>% tamp())
```

## Migrate spatial variables to a long cubble

As a final data output for modelling or visualisation, spatio-temporal data is usually expected to be in a single table. Function `migrate()` moves the spatial variables from the `spatial` attribute into the long cubble:

```{r}
(cubble_long %>% migrate(long, lat))
```

In this workflow described above, data objects come into cubble in the nested form, then various operations on the spatial and temporal dimension can go back and forth between the nested and long form, and finally, the data will come out of cubble in the long form for further modelling or visualisation.

Building from an underlying `tbl_df` structure, it is natural to implement methods available in `dplyr` to `cubble`. Supported methods in the `cubble` with `dplyr` generics includes:

```{=tex}
\begin{center}
\begin{tabular}{ | m{5em} | m{15cm}| } 
basics & \textbf{mutate}, \textbf{filter}, \textbf{summarise}, \textbf{select}, \textbf{arrange}, \textbf{rename}, \textbf{left\_join} \\
grouping &  \textbf{group\_by}, \textbf{ungroup}\\
slice family & \textbf{slice\_head}, \textbf{slice\_tail}, \textbf{slice\_sample}, \textbf{slice\_min} and \textbf{slice\_max} \\
\end{tabular}
\end{center}
```
\pkg{cubble} is also compatible with \pkg{tsibble} in the sense that the original list-column can be a `tbl_ts` object. Duplicates and gaps should be first checked before structuring the data into a cubble. If the input data is a \pkg{tsibble} object, the long form cubble is also a \pkg{tsibble} where users can directly apply time series operations.

# Advanced features/ considerations

## Hierarchical structure

`switch_key()`

## Data fusion and matching

## Interactive graphics

Interactive graphics can listen to users' actions on the plot to provide additional information that facilitates data exploration. This is a useful technique for spatio-temporal data since users can zoom or pan the map to view the local and global structure of the map; use tooltips or popups to query more information about a graphic element; or highlight points to explore its linked views in other plots. In the R community, many implementations have been developed to connect \proglang{R} to \proglang{javascript} to create interactive graphics. In relation to spatio, temporal, and spatio-temporal data, the general purpose packages \pkg{plotly} [@plotly] and \pkg{leaflet} [@leaflet] realise various interactive actions through their corresponding javascript libraries. \pkg{crosstalk} [@crosstalk] and \pkg{tsibbletalk} [@tsibbletalk] implement brushed linking between htmlwidgets. \pkg{ggiraph} [@ggiraph] enables tooltip, self-linking, and customised actions specified through its own \proglang{javascript}. 

While many graphic implementations present worked examples to illustrate the usage of the package, few documents the underlying pipeline that transforms the raw data step-by-step to the final view on the screen. There have been some early work in building the data pipeline for (interactive) graphics [@buja1988elements; @buja1996interactive;  @sutherland2000orca] and more recent discussions include @wickham2009plumbing, @xie2014reactive, and @cheng2016enabling.

Figure \ref{fig:interactive-workflow} shows how cross-linking works with the two forms in a cubble. The data pipeline flows from the *Augmented Data* to *Transformation*, and then *Subset*, to finally, *Plot*. This data pipeline, proposed by @wickham2009plumbing, places the *Subset* stage as the last step before *Plot* so that each plot can be made separately from different subsets. This design fits naturally with cubble where the spatial map is solely made from the nested form and the time series plot can be created from the long form. When a user action is captured either from the map or the time series, the relevant row will be highlighted in the data and all the observations that shares the same `key` variable (`id`), in both forms, will then be highlighted. This type of linking is called categorical linking [@xie2014reactive], which is a one-to-many linking through highlighting observations within the same category. 

```{r interactive-workflow, echo = FALSE, fig.align="center", out.height="40%", out.width = "100%", fig.cap = "demon interactivity"}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.003.png"))
```


<!-- communicates the user action down the workflow to [...]. Various such workflow has been proposed in the 90s literature, including [...]. These designs do the linking as follows: when an user action is)) captured, the system searches for the unique identifiers of that observation, and fetches the queried information with the same unique identifiers. -->

\newpage

# Examples

## Australia precipitation pattern in 2020

Forming a cubble + basic tidyverse verbs - Vig 2 Aggregation - Vig 4

This vignette introduces how to perform spatial and temporal manipulate in a cubble with dplyr verbs. We will illustrate with `weatherdata::historical_tmax` data, which have the historical maximum temperature recorded for Australian stations with the earliest dating back to 1859.

### Spatial manipulation

`historical_tmax` is already in a nested cubble format, which is suitable for station-wise manipulation. `rnoaa` construct the station id by prefix `ASN00` to the Bureau of Meteorology (BOM) station number. In [BOM's numbering system](http://www.bom.gov.au/climate/cdo/about/site-num.shtml), the 2nd and 3rd digit denotes the state a station is located in and this is equivalent to the 7th to 8th digit in our string. We can mutate/ filter station in a particular state based on this information and here we add a column called `state_id` and filter out the ones in New South Wales and Victoria (ranging from 46 to 90).

```{r}
tmax_nested <- weatherdata::historical_tmax %>%
  mutate(state_id = stringr::str_sub(id, 7, 8)) %>%
  filter(between(state_id, 46, 90))
```

### Temporal manipulation

There are some operations in the time dimension we would like to make:

-   Extract observations in a particular period, say, those in 1971 to 1975 and 2016 to 2020. This can be used to compare the historical and recent climate.
-   Summarise daily records into monthly to remove sparsity

These time dimension operations can be computed in the long form and `stretch()` converts a nested cubble to a long cubble. From a long cubble, we can write the exact same dplyr codes to complete the two tasks:

```{r}
tmax_long <- tmax_nested %>%
  stretch() %>%
  filter(lubridate::year(date) %in% c(1971:1975, 2016:2020)) %>%
  mutate(
    month = lubridate::month(date),
    group = as.factor(ifelse(
      lubridate::year(date) > 2015,
      "2016 ~ 2020",
      "1971 ~ 1975"
    ))
  ) %>%
  group_by(month, group) %>%
  summarise(tmax = mean(tmax, na.rm = TRUE))
```

### Back to spatial

A data quality issue with the `rnoaa` data is that while it records the first and last year recorded of each series, it doesn't report the period of missingness. For example, station `ASN00047048` starts it first record in 1957, pauses for a period from 1963 to 1990, and then resumes it recording till today. Out of the `r nrow(tmax_nested)` stations in New South Wales and Victoria, 7 stations have this issue and we would like to remove those stations from the comparison.

Again, this is a station-wise operation and to convert back from the long cubble to a nested one, use `tamp()`. Here we keep the stations with 24 observations (12 months for both periods) after the monthly aggregation.

```{r}
tmax_nested2 <- tmax_long %>%
  tamp() %>%
  filter(nrow(ts) == 24)
```

In some visualisation, we may need information from both spatial and temporal dimension. One example of this is a glyph map, where spatial variables, i.e. `longitude` and `latitude`, are used to construct the major axes and temporal variables, i.e. `month` and `tmax`, are used to construct the minor axes. This requires these variables to be in the same table, rather than in different forms. In cubble, you can append spatial variables that are invariant to the `key` with `migrate()`

```{r}
tmax_long2 <- tmax_nested2 %>%
  stretch() %>%
  migrate(latitude, longitude)
```

### Glyph map

Now its time for the glyph map!

```{r echo = FALSE}
gly <- glyphs(
  tmax_long2,
  x_major = "longitude",
  y_major = "latitude",
  x_minor = "month",
  y_minor = "tmax",
  height = 0.6,
  width = 1
)

nsw_vic <- ozmaps::abs_ste %>%
  filter(NAME %in% c("Victoria", "New South Wales"))

plot_map(nsw_vic, fill = "transparent") +
  geom_path(data = gly, aes(gx, gy,
    group = interaction(id, group),
    color = group
  )) +
  scale_color_brewer(palette = "Dark2") + 
  theme_bw() + 
  coord_sf(xlim = c(140, 155)) + 
  theme(legend.position = "bottom")
```

## Spatial and temporal aggregation

On top of `aus_climate` data in this package, `climate_full` from package [`weatherdata`](https://github.com/huizezhang-sherry/weatherdata) has daily climate data of `r nrow(weatherdata::climate_full)` Australia stations from 2016 to 2020. This is where these stations locate in an Australia map:

This is a lot of stations to look at for one climate variable and they can't all fit into a glyph map. What we can do is to group stations into clusters and look at the aggregated series in the glyph map. In this vignette, I will introduce how to perform spatial (and temporal) aggregation using hierarchical data structure in cubble.

First let's add a new column `ll` for calculating distance matrix in the next section and aggregate the daily precipitation into weekly measure. These steps should be familiar from the vignette *Data manipulation with cubble*.

```{r}
station_nested <- weatherdata::climate_full %>%
  mutate(ll = s2::s2_lnglat(long, lat)) %>%
  stretch() %>%
  mutate(wk = lubridate::week(date)) %>%
  group_by(wk) %>%
  summarise(prcp = sum(prcp, na.rm = TRUE)) %>%
  tamp()
```

### Hierarchical data structure

Imposing a clustering structure can be thought of as building a hierarchical structure where stations are nested within clusters. As an example to illustrate here, we use a kmean clustering algorithm based on the distance matrix and specify the number of centres to be 20. More complex algorithms can also be used for more complex problem, as long as a mapping from each station id to the cluster id can be constructed. We then join this data to our station data:

```{r}
dist_raw <- scale(s2::s2_distance_matrix(station_nested$ll, station_nested$ll))

cluster_res <- tibble(
  id = station_nested$id,
  cluster = kmeans(dist_raw, centers = 20, nstart = 50)$cluster
)

station_nested <- station_nested %>%
  left_join(cluster_res)
```

One thing we hope to do with the cluster is to find the coordinates of the centroid. These are variables variant to the station but invariant to the cluster and it would be nice to have a function that structure each cluster as a row. `switch_key()` is the function that does this: it lets you to specify a new key, say `cluster` and nests all spatial variables variant to `cluster` into a column. Temporal observations from different stations while within the same cluster are bound in the nested column `ts`.

```{r}
cluster_nested <- station_nested %>%
  switch_key(cluster)
```

This structure makes it easy to compute cluster level variable, although there are a few steps to calculate the centroid coordinates: we need to find the convex hull that wraps around the cluster, make it a polygon, find the centroid of the polygon and finally, extract the x and y coordinate of each centroid:

```{r}
cluster_nested <- cluster_nested %>%
  mutate(
    chull = list(chull(.val$long, .val$lat)),
    ll_cluster = sf::st_as_sfc(
      s2::s2_make_polygon(c(.val$long[chull]),
        c(.val$lat[chull]),
        oriented = FALSE
      )
    ),
    centroid = s2::s2_centroid(ll_cluster),
    cent_long = s2::s2_x(centroid),
    cent_lat = s2::s2_y(centroid)
  )
```

After we have got `cluster_nested`, spatial and temporal data at both levels can be easily obtained. If we use `station` and `cluster` prefix to denote the two levels and `nested` and `long` for whether the data shows the spatial or temporal dimension, the relationship among the four datasets can be illustrated in the following workflow:

Start with the original `station_nested`, `stretch()` expands the `ts` column with each station (`id`) forming a group and attach variables invariant to `id` as an attribute. `switch_key()` changes the `key` from `id` to `cluster` and nests all the spatial variables that variant to `cluster`. `stretch()` `cluster_nested` will store variables that are invariant to `cluster` as a tibble in the attribute.

Now we can obtain the aggregated series as described in the workflow diagram above and construct the glyph map with `GGally::glyphs()`:

```{r echo = FALSE}
cluster_long <- cluster_nested %>%
  stretch(ts) %>%
  group_by(wk) %>%
  summarise(prcp = sum(prcp, na.rm = TRUE)) %>%
  migrate(cent_long, cent_lat)

gly <- GGally::glyphs(cluster_long,
  x_major = "cent_long", x_minor = "wk",
  y_major = "cent_lat", y_minor = "prcp",
  height = 2, width = 4
)

state_map <- rmapshaper::ms_simplify(ozmaps::abs_ste, keep = 2e-3)
plot_map(state_map) +
  geom_text(
    data = cluster_nested,
    aes(x = cent_long, y = cent_lat, label = cluster)
  ) +
  geom_path(
    data = gly,
    aes(x = gx, y = gy, group = gid)
  )
```

We can also look at the precipitation of each individual station within the same cluster:

```{r fig.height = 5, fig.cap = "shtishisa", echo = FALSE}
station_long <- station_nested %>%
  stretch(ts) %>%
  migrate(cluster)
station_long %>%
  ggplot(aes(x = wk, y = prcp, group = id)) +
  geom_line(alpha = .3) +
  facet_wrap(vars(cluster), scales = "free_y", ncol = 4) +
  theme_bw()
```

Lastly, there is one series on Tasmania island standing out from others, lets look at where it is:

```{r echo = FALSE}
# this part still needs some fixing
tas_latlong <- station_nested %>%
  filter(lat < -40) %>%
  mutate(p = max(ts$prcp)) %>%
  strip_rowwise() %>%
  filter(p == max(p))

state_map <- rmapshaper::ms_simplify(ozmaps::abs_ste, keep = 2e-3)
plot_map(state_map) +
  geom_point(data = station_nested, aes(x = long, y = lat), size = 0.5) +
  geom_sf(data = cluster_nested, aes(geometry = ll_cluster), fill = "transparent") +
  geom_point(data = tas_latlong, aes(x = long, y = lat), col = "red")
```

## Matching precipitation and river level in Victria water gauges

The water level data comes from [Bureau of Meteorology](http://www.bom.gov.au/metadata/catalogue/19115/ANZCW0503900528?template=full) and has a copy in `weatherdata`. Here we extract the water course level and add a column annotate this data of type `river`. For the rainfall data, we will still use the `weatherdata::climate_full`, filtering for Victorian stations in 2020 should be pretty familiar by now. Again, we first look at where these stations are on the map first:

```{r echo = FALSE}
river <- weatherdata::water %>%
  stretch() %>%
  select(date, Water_course_level) %>%
  tamp() %>%
  mutate(type = "river")

climate <- weatherdata::climate_full %>%
  filter(between(stringr::str_sub(id, 7, 8), 76, 90)) %>%
  stretch() %>%
  filter(lubridate::year(date) == 2020) %>%
  tamp() %>%
  mutate(type = "climate")

vic_map <- rmapshaper::ms_simplify(ozmaps::abs_ste %>% filter(NAME == "Victoria"))
plot_map(vic_map) +
  geom_point(
    data = dplyr::bind_rows(river, climate),
    aes(x = long, y = lat, color = type)
  ) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw()
```

### Theory

Temporal matching checks how spatially matched pairs align temporally. We use the following chart to illustrate how the temporal matching works:

```{r echo = FALSE, fig.height=3, fig.cap = "shtishisaasdf"}
set.seed(123)
dt <- tibble(
  id = factor(c(rep("A", 31), rep("a", 31)), levels = c("A", "a")),
  date = rep(1:31, 2),
  val = c(
    c(rnorm(5), 10, rnorm(7), 5, rnorm(8), 7, rnorm(8)),
    c(
      rnorm(6, sd = 0.5), 7, rnorm(7, sd = 0.5), rnorm(6, sd = 0.5),
      4, rnorm(5, sd = 0.5), 6, rnorm(4, sd = 0.5)
    )
  )
) %>% mutate(val = ifelse(val < 0, 0, val))

circle <- tibble(
  x = c(6, 14, 23, 7, 21, 27),
  y = c(10, 5, 7, 7, 4, 6),
  id = factor(c(rep("A", 3), rep("a", 3)), levels = c("A", "a")),
  xend = x + 5
)

errorbar <- bind_rows(
  circle %>% filter(id == "A"),
  circle %>% filter(id == "A") %>% mutate(id = "a")
) %>%
  mutate(id = factor(id, c("A", "a")))

fallin <- tibble(
  id = factor(rep("a", 2), c("A", "a")),
  x = c(7, 27),
  y = -0.5,
  label = "\U2714"
)

ggplot() +
  geom_line(data = dt, aes(x = date, y = val, group = id), color = "grey60") +
  geom_vline(data = circle, aes(xintercept = x), linetype = "longdash", color = "grey60") +
  geom_errorbar(data = errorbar, aes(xmin = x, xmax = xend, y = -0.5), width = 0.5) +
  geom_point(data = circle, aes(x = x, y = y), color = "brown") +
  geom_text(data = fallin, aes(x = x, y = y, label = label), color = "brown", size = 5) +
  facet_wrap(vars(id), nrow = 2) +
  scale_y_continuous(breaks = seq(0, 10, 2)) +
  scale_x_continuous(breaks = seq(1, 31, 1)) +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  labs(x = "Time", y = "Value")
```

For each spatially matched pair, say `A` and `a`, we first find the largest `n` points in each series, colored in brown points here. Here we use the largest three but you can tune this number by `temporal_n_highest`. Then we construct the interval of the largest points from one series and see how many points, from the other series, fall into the intervals. The series used to construct the interval is controlled by `temporal_independent` and the window size by `temporal_window` with a default of 5.

In this illustration, we construct the interval based on series `A` and two of the three peaks from `a` falls into this interval at Time 7 and 27.

### Rainfall translates into river level

There's another mandatory argument that hasn't been introduced above: `temporal_var_to_match`. This argument controls the variable to match and it needs to appear in both the `major` and `minor` set. In the water level matching example, we match the variable `Water_course_level` from `river` to `prcp` from `climate`, hence need to manually rename one of them to match the other, here we rename `Water_course_level` to `prcp` in `river`:

```{r}
river <- river %>%
  stretch() %>%
  rename(prcp = Water_course_level) %>%
  tamp()
```

Now we use `match_sites()` to first pair the weather stations with the river gauges spatially and then apply the temporal matching on `prcp`. We will construct the interval based on peaks in `climate` since we would expect a lag effect for precipitation to flow into the river and cause a raise in river level, hence `temporal_independent = climate`. We select the 30 highest peak from the series to construct the match by setting `temporal_n_highest = 30`. This is a tuning parameter and you can start with 10% of the points of one series (here we have daily data for a year, 10% is roughly 30 points). `temporal_min_match` filters out pairs don't have enough match and to return all the pairs, set `temporal_min_match` to `0`.

```{r}
res <- match_sites(river, climate,
  temporal_var_to_match = prcp,
  temporal_independent = climate,  
  temporal_n_highest = 30,
  temporal_min_match = 15
)

res
```

The output from temporal matching is also a cubble, with additional column `.dist` and `.group` inherent from spatial matching and `n_match` for the number of matched temporal peaks. Then you can use this output to plot the location of match or to look at the series:

```{r echo = FALSE, out.width="100%", fig.cap="..."}
p1 <- plot_map(vic_map) +
  geom_point(
    data = res,
    aes(x = long, y = lat, color = type)
  ) +
  ggrepel::geom_label_repel(
    data = res %>% filter(type == "river"),
    aes(x = long, y = lat, label = .group)
  ) +
  scale_color_brewer(palette = "Dark2") +
  ggtitle("Victoria") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    legend.position = "bottom"
  )

res_long <- res %>%
  stretch(ts) %>%
  migrate(.group, type) %>%
  mutate(prcp = scale(prcp)[, 1]) %>%
  switch_key(.group) %>%
  migrate(type)

p2 <- res_long %>%
  ggplot(aes(
    x = date, y = prcp,
    group = id, color = type
  )) +
  geom_line() +
  facet_wrap(vars(.group)) +
  scale_color_brewer(palette = "Dark2", guide = "none") +
  theme_bw() +
  labs(x = "week") +
  scale_x_date(date_labels = "%b")

p1 | p2
```

## Spatio-temporal data with NetCDF

```{r}
nc <- ncdf4::nc_open(here::here("data/adaptor.mars.internal-1638344933.932894-4194-11-a5d35ac3-b36d-4982-afa5-a5dd193a6718.nc"))
temp <- as_cubble(nc, vars = "d2m")
vic_map <- ozmaps::abs_ste %>% filter(NAME == "Victoria")

res <- temp %>% 
  stretch(ts) %>% 
  mutate(d2m = d2m - 273.15) %>% 
  filter(lubridate::hour(time) == 12) %>% 
  group_by(id) %>% 
  summarise(d2m = mean(d2m, na.rm= TRUE)) %>%
  migrate(long, lat)

vic_string <- vic_map %>% sf::st_cast("MULTILINESTRING") 

res %>% 
  ggplot() +
  geom_tile(aes(x = long, y = lat, fill = d2m)) +
  geom_sf(data = vic_string , alpha = 0.5, fill = "transparent") +
  theme_bw() + 
  colorspace::scale_fill_continuous_sequential("Mint")

```

## Interative graphic with cubble

```{r echo = FALSE, out.width="100%", out.height="30%"}
knitr::include_graphics(here::here("figures/linking.png"))
```


```{r echo = FALSE, out.width="50%", out.height="30%"}
knitr::include_graphics(here::here("figures/popup.png"))
```


# Conclusion

\newpage

# Old stuff

In the temporal aspect, the `tsibble` [@tsibbles] structure and its tidyverts ecosystem have provided a [... ] workflow to work with temporal data. In a tsibble structure, temporal data is characterised by `index` and `key` where `index` is the temporal identifier and `key` is the identifier for multiple series, which could be used as a spatio identifier. However, a tsibble object, by construction, always requires the `index` in its structure. This makes it less appealing for spatio-temporal data since the output of calculated spatio-specific variables (i.e. features of each series) don't have the time dimension. Analysts will either need to have an additional step to join this output to the original tsibble or operate with variables stored in two separate objects. In addition, the long form structure of a tsibble object means spatio variables (i.e. longitude, latitude, and features of each series if joined back to the tsibble) of each spatio identifier will be repetitively recorded at each timestamp. This repetition is unnecessary and would inflate the object size for long series.

# Create a cubble

The creation of a cubble requires the site identifier (`key`), as well as the spatial (`coords`) and temporal (`index`) identifier. `climate_flat` is already a tibble and it uses `id` to identify each station, `date` as the time identifier, and `c(long, lat)` as the spatial identifier. To create a cubble for this data, use:

```{r}
climate_flat %>% as_cubble(key = id, index = date, coords = c(long, lat))
```

Most of the time, spatio-temporal data doesn't come into this form and analysts need to query the climate variables based on station metadata. \textcolor{red}{This is also a problem illustrated in Section 3.5 in @tidydata. Here we provide a structured way to query this data based on the row-wise operator and nested list.} For this type of task, one can structure a metadata into a tibble and use row-wise operator to query the climate variables into a nested list. As an example here we demonstrate the workflow to find the 5 closest stations to Melbourne. We first create a station data frame with the 5 target stations.

```{r echo = FALSE}
latlon_ref <- tibble::tibble(id = "melbourne", lat = -37.8136, long = 144.9631)

cand <- aus_climate %>%
  as_tibble() %>%
  select(id, lat, long, elev, name, wmo_id)


calc_dist <- function(df_ref, df, n = 5) {
  long_ref <- df_ref$long
  lat_ref <- df_ref$lat

  df %>%
    mutate(
      long_ref = long_ref,
      lat_ref = lat_ref,
      dist = rnoaa::meteo_spherical_distance(lat, long, lat_ref, long_ref)
    ) %>%
    slice_min(dist, n = n) %>%
    mutate(city = df_ref$id) %>%
    select(-long_ref, -lat_ref)
}

(stations <- do.call("rbind", purrr::map(
  1:nrow(latlon_ref),
  ~ calc_dist(latlon_ref[.x, ], cand)
)))
```

We can query the climate information into a nested list named `ts` for each station with the `rowwise()` operator. To create a cubble, supply the same identifiers as with the first example.

```{r eval = FALSE}
sydmel_climate <- stations %>%
  rowwise() %>%
  mutate(ts = list(meteo_pull_monitors(id,
    date_min = "2020-01-01",
    date_max = "2020-12-31",
    var = c("PRCP", "TMAX", "TMIN")
  ) %>%
    select(-id))) %>%
  as_cubble(key = id, index = date, coords = c(long, lat))
```

```{r echo = FALSE}
(sydmel_climate <- stations %>%
  left_join(aus_climate) %>%
  as_cubble(key = id, index = date, coords = c(long, lat)))
```

Below are the how the nested and long form look like for Australia climate data, which records daily precipitation, maximum and minimum temperature for 55 stations across Australia from 2015- 2020. Notice that each station forms a group in both forms and specifically, the nested and long form have a underlying `rowwise_df` and `grouped_df` respectively.

With a cubic framework on mind, different types of manipulation with cubble can be thought of as slicing the cube in various way. The table below shows how some `dplyr` verbs are mapped into the operation in a cubble. With the existing grouping on the station, additional grouping can be added with `group_by` and removed with `ungrouped`. [talk about why it is useful]

\newpage

## Cubble operations

```{r cubble-operations, echo = FALSE, fig.cap="Cubble operations", out.height="50%", out.width="90%", fig.align='center'}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.004.png"))
```
