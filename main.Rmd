---
documentclass: jss
author:
  - name: H. Sherry Zhang
    # department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    #location: Melbourne, Australia
    email: \email{huize.zhang@monash.edu}
  - name: Dianne Cook
    # department: Department of Econometrics and Business Statistics
    affiliation: 'Monash University \AND'
    # location: Melbourne, Australia
    # email:  dicook@monash.edu
  - name: Ursula Laa
    # department: Institute of Statistics
    affiliation: 'University of Natural Resources and Life Sciences \AND'
    # location: Vienna, Austria
    # email:  ursula.laa@boku.ac.at
  - name: Nicolas Langrené
    # department: 34 Village Street, Docklands VIC 3008 Australia
    affiliation: 'CSIRO Data61 \AND'
    # location: Melbourne, Australia
    # email: nicolas.langrene@csiro.au
  - name: Patricia Menéndez
    # department: Department of Econometrics and Business Statistics
    affiliation: 'Monash University \AND'
    # location: Melbourne, Australia
    # email:  patricia.menendez@monash.edu
title:
  formatted: "\\pkg{cubble}: An R Package for Structuring Spatio-temporal Data"
  # If you use tex in the formatted title, alsoge supply version without
  plain:     "cubble: An R Package for Structuring Spatio-temporal Data"
  # For running headers, if needed
  # short:     "\\pkg{foo}: A Capitalized Title"
abstract: >
  The abstract of the article.
keywords:
  # at least one keyword must be supplied
  formatted: [spatio-temporal data,  "\\proglang{R}"]
  plain:     [spatio-temporal data, R]
preamble: >
  \usepackage{amsmath}
  \usepackage{array}
output: rticles::jss_article
bibliography: references.bib
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.path = "figures/",
  fig.height = 10
)
options(prompt = "R> ", continue = "+ ")
```

```{r echo = FALSE}
library(cubble)
library(forcats)
library(stringr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(GGally)
library(plotly)
library(crosstalk)
library(patchwork)
```

\newpage

# Introduction

**Motivation**  

Many data structures have been proposed for spatial (`sf` by @sf) and temporal (`tsibble` by @tsibble) data in the R community, while less has been done for spatio-temporal data. The lack of such tools could potentially  because analysts usually treat the spatial and temporal dimension pf the data separately, without realising the need to create a new data structure. While this approach follows the third tidy data principal [@tidydata] (*Each type of observational unit forms a table*), analysts always need to manually join results from different observational units or combining multiple tables into one for downstream analysis. This additional step doesn't add new operations into the data but can be error prone.  \newline

**Existing packages**  

Currently, available spatio-temporal data structure in R includes: `spacetime`[@spacetime], which proposes four space-time layouts: Full grid (STF), sparse grid(STS), irregular (STI), and trajectory (STT). The data structure it uses is based on `sp` [@sp] and `xts`[@xts], both of which has been replaced by more recent implementations. `spatstat` [@spatstat] implements a `ppp` class for point pattern data; and more recent, `stars` [@stars] implements a spatio-temporal array with the dplyr's data cube structure `cubelyr` [@cubelyr] as its backend. While these implementations either store spatial and temporal variables all in a single table, hence duplicate the spatial variables for each temporal unit; or split them into two separate tables that has the problem of manually joining, mentioned in the previously. None of these packages enjoy both the benefits of being able to separate manipulation in the two dimensions while also keep the data object as a whole. This create a gap in the software development. The requirement for such a tool is important given the ubiquity of spatio-temporal vector data in the wild: the Ireland wind data from `gstat` is an classic example data that splits variables into spatial (`wind.loc`) and temporal (`wind`) dimension; Bureau of Meteorology (BoM) provides climate observations that are widely applied in agriculture and ecology study; air pollution data. \newline

**Our new data structure for spatio-temporal data**  
This paper describes the implementation of a new spatio-temporal data structure: `cubble`. `cubble` implements a relational data structure that uses two forms to manage the switch between spatial and temporal dimension. With this structure, users can manipulate the spatial or temporal dimension separately, while leaves the linking of two dimensions to `cubble`. The software is available from the Comprehensive R Archive Network (CRAN) at [CRAN link]. \newline

**Section division**  

The rest of the paper will be divided as follows: [complete when the paper structure is more solid]

<!-- Section 2 reviews the existing data structure for spatio, temporal, and spatio-temporal data. Section 3 presents a new data structure for spatio-temporal data: cubble. Then the paper introduces the workflow of data manipulation and visualisation with the cubble structure in Section 4. Section 5 gives some examples on how common spatial and temporal manipulations are performed with cubble and how static and interactive visualisation help to understand climate and [...] data. \newline -->

\newpage
# The cubble package

Spatio-temporal data usually come in various forms and Figure \ref{fig:cubble-diagram} shows four examples of this. No matter whichever form the data is in, there are always some common components shared by these data. A spatial identifier (`id` in the diagram) identifies each site. The temporal identifier (`t` in the diagram) [...]. Coordinates, comprising of latitude and longitude, are commonly used variables for point pattern data.These identifiers will be the building blocks for the data structure introduced below. For other variables, those invariant at each time stamp are spatial variables and those differ are temporal variables.

```{r cubble-diagram, echo = FALSE, out.width = "100%", out.height = "30%", fig.cap="Illustration of incoming data formats for spatio-temporal data. (1) Data comes in as a single table; (2) Separate tables for spatial and temporal variables; (3) A single table with all the parameters used to query the database and a separate table for queried data; and (4) Cubical data in array or NetCDF format.", fig.align='center', out.height = "15%"}
knitr::include_graphics(here::here("figures/input-formats/input-formats.001.png"))
```

In a cubble, there are two forms: 1) nested form, for manipulating the spatial dimension, and 2) long form, for manipulating the temporal dimension. Figure \ref{fig:def-cubble} sketches the two forms along with the associated attributes. A variable identifies by the spatial identifies can come from manipulating spatial variables itself, or summary of temporal variables. The nested cubble is best suited to work with this type of operation, since it defines each spatial unit as a row. The spatial variables are directly displayed in columns. Temporal variables are nested in a column called `ts` and the underlying rowwise dataframe uses a `group` attributes to ensure each row  is in its own group. 

<!-- In this structure, the nested form is suitable for manipulating the spatial dimension of the data and this would include manipulating variables that 1) are inherently spatial and 2) summarise the temporal variables by `key`. Under the hood, the nested cubble is built on top of the rowwise dataframe (`rowwise_df`). This is design to simplify the code when working with the temporal variables - they are nested into the list-column `ts`. -->


Temporal operations are suited to be performed in the long cubble as each row is defines as the combination of spatial and temporal identifier. This is also the structure that `tsibble` adopts. Temporal variables are directly displayed. To avoid repeating the same spatial at each temporal unit, all the spatial variables, along with the spatial identifier, are stored as a `spatial` attributes. This information is used when switching back to the nested form.

```{r def-cubble, echo = FALSE, fig.align="center", out.height="30%", out.width = "100%", fig.cap = "Illustration of nested and long cubble."}
knitr::include_graphics(here::here("figures/def-cubble/def-cubble.001.png"))
```

\newpage
## Create a cubble in the nested form

To use functionalities from cubble, data analysts first need to create a cubble. `as_cubble` create a `cubble` by supplying the three key components: `key` as the spatial identifier; `index` as the temporal identifier; and a vector of `coords` in the order of longitude first and then latitude. The use of `key` and `index` follows the naming convention in `tsibble`. The cubble created by default is in the nested form. Below is an example of creating a cubble:  \newline

```{r}
(cubble_nested <- cubble::climate_flat %>%
  as_cubble(key = id, index = date, coords = c("long", "lat")))
```

In the `cubble` header, you can read the name of the `key` variable, bbox, and also the name of variable nested in the `ts` column. In this example, the spatial identifier is `id` and the number in the bracket means there are 5 unique `id` in this dataset. The bbox in the second row gives the range of the coordinates. The temporal variables are all nested in the `ts` column, but it could be useful to know the name these variables. The third row in the cubble header shows these names and in this example this includes: precipitation, `prcp`, maximum temporature, `tmax`, and minimum temperature, `tmin`.

## Stretch a nested cubble into the long form

From a created cubble in the nested form, analysts may want to directly manipulate the temporal variables. This would require switching to the long form using `stretch()`. The verb `stretch()` switch the cubble from the nested form into a long form. Under the hood, it first extracts the spatial variables into a separate tibble to store in the attribute `spatial` and then unnests the `ts` column to show the temporal content: 

```{r}
(cubble_long <- cubble_nested %>% stretch(ts))
```

Notice here that the third line in the header is changed to reflect the spatial variables stored. This is a format suitable for computing time-wise variables. 

## Tamp a long cubble back to the nested form

Manipulation on the spatial and temporal dimension can be an iterative process. Many times, we may decide to go back to the nested form after some temporal manipulation. The verb to switch a long cubble back to the nested form is `tamp()`:

```{r}
(cubble_back <- cubble_long %>% tamp())
```

## Migrate spatial variables to a long cubble

As an output to be supplied to further visualisation or modelling, analysts would usually like the spatial and temporal variables to be in the same table. `migrate()` moves the spatial variables in the attribute `spatial` into the long form cubble.  

```{r}
(cubble_long %>% migrate(long, lat))
```

## Support on hierarchical structure

`switch_key()`

## Support on interactive graphics

## Integrating into a tidy workflow

Building from an underlying `tbl_df` structure, it is natural to implement methods available in `dplyr` to `cubble`. Supported methods in the `cubble` with `dplyr` generics includes: 

\begin{center}
\begin{tabular}{ | m{5em} | m{15cm}| } 
\textbf{mutate} \\
\textbf{filter}\\
\textbf{summarise} \\
\textbf{select} \\
\textbf{arrange} \\
\textbf{rename} \\
\textbf{left\_join} \\
\textbf{group\_by} \\
\textbf{ungroup}\\
slice family & \textbf{slice\_head}, \textbf{slice\_tail}, \textbf{slice\_sample}, \textbf{slice\_min} and \textbf{slice\_max} \\
\end{tabular}
\end{center}

`cubble` is also compatible with `tsibble` in the sense that the original list-column can be a `tbl_ts` object. Duplicates and gaps shoudl be first checked before structuring the data into a cubble. If the input data is a `tsibble` object, the long form cubble is also a `tsibble` where users can directly apply time series operations.


\newpage

# Examples

## Australia precipitation pattern in 2020

Forming a cubble + basic tidyverse verbs - Vig 2
Aggregation  - Vig 4

This vignette introduces how to perform spatial and temporal manipulate in a cubble with dplyr verbs. We will illustrate with `weatherdata::historical_tmax` data, which have the historical maximum temperature recorded for Australian stations with the earliest dating back to 1859.

### Spatial manipulation 

`historical_tmax` is already in a nested cubble format, which is suitable for station-wise manipulation. `rnoaa` construct the station id by prefix `ASN00` to the Bureau of Meteorology (BOM) station number. In  [BOM's numbering system](http://www.bom.gov.au/climate/cdo/about/site-num.shtml), the 2nd and 3rd digit denotes the state a station is located in and this is equivalent to the 7th to 8th digit in our string. We can mutate/ filter station in a particular state based on this information and here we add a column called `state_id` and filter out the ones in New South Wales and Victoria (ranging from 46 to 90). 

```{r}
tmax_nested <- weatherdata::historical_tmax %>%
  mutate(state_id = stringr::str_sub(id, 7, 8)) %>%
  filter(between(state_id, 46, 90))
```

### Temporal manipulation 

There are some operations in the time dimension we would like to make:

  - Extract observations in a particular period, say, those in 1971 to 1975 and 2016 to 2020. This can be used to compare the historical and recent climate. 
  - Summarise daily records into monthly to remove sparsity
  
These time dimension operations can be computed in the long form and `stretch()` converts a nested cubble to a long cubble. From a long cubble, we can write the exact  same dplyr codes to complete the two tasks: 

```{r}
tmax_long <- tmax_nested %>%
  stretch() %>%
  filter(lubridate::year(date) %in% c(1971:1975, 2016:2020)) %>%
  mutate(
    month = lubridate::month(date),
    group = as.factor(ifelse(
      lubridate::year(date) > 2015,
      "2016 ~ 2020",
      "1971 ~ 1975"
    ))
  ) %>%
  group_by(month, group) %>%
  summarise(tmax = mean(tmax, na.rm = TRUE))
```

### Back to spatial

A data quality issue with the `rnoaa` data is that while it records the first and last year recorded of each series,  it doesn't report the period of missingness. For example, station `ASN00047048` starts it first record in 1957, pauses for a period from 1963 to 1990, and then resumes it recording till today. Out of the `r nrow(tmax_nested)` stations in New South Wales and Victoria, 7 stations have this issue and we would like to remove those stations from the comparison.

Again, this is a station-wise operation and to convert back from the long cubble to a nested one, use `tamp()`. Here we keep the stations with 24 observations (12 months for both periods) after the monthly aggregation.

```{r}
tmax_nested2 <- tmax_long %>%
  tamp() %>%
  filter(nrow(ts) == 24)
```

In some visualisation, we may need information from both spatial and temporal dimension. One example of this is a glyph map, where spatial variables, i.e. `longitude` and `latitude`, are used to construct the major axes and temporal variables, i.e. `month` and `tmax`, are used to construct the minor axes. This requires these variables to be in the same table, rather than in different forms. In cubble, you can append spatial variables that are invariant to the `key` withe `migrate()`


```{r}
tmax_long2 <- tmax_nested2 %>%
  stretch() %>%
  migrate(latitude, longitude)
```


### Glyph map

Now its time for the glyph map! 

```{r}
gly <- glyphs(
  tmax_long2,
  x_major = "longitude",
  y_major = "latitude",
  x_minor = "month",
  y_minor = "tmax",
  height = 0.6,
  width = 1
)

nsw_vic <- ozmaps::abs_ste %>%
  filter(NAME %in% c("Victoria", "New South Wales"))

plot_map(nsw_vic, fill = "transparent") +
  geom_path(data = gly, aes(gx, gy,
    group = interaction(id, group),
    color = group
  )) +
  scale_color_brewer(palette = "Dark2") + 
  theme_bw() + 
  coord_sf(xlim = c(140, 155)) + 
  theme(legend.position = "bottom")
```

## Spatial and temporal aggregation


On top of `aus_climate` data in this package, `climate_full` from package [`weatherdata`](https://github.com/huizezhang-sherry/weatherdata) has daily climate data of `r nrow(weatherdata::climate_full)` Australia stations from 2016 to 2020. This is where these stations locate in an Australia map: 

This is a lot of stations to look at for one climate variable and they can't all fit into a glyph map. What we can do is to group stations into clusters and look at the aggregated series in the glyph map. In this vignette, I will introduce how to perform spatial (and temporal) aggregation using hierarchical data structure in cubble. 

First let's add a new column `ll` for calculating distance matrix in the next section and aggregate the daily precipitation into weekly measure. These steps should be familiar from the vignette *Data manipulation with cubble*.

```{r}
station_nested <- weatherdata::climate_full %>%
  mutate(ll = s2::s2_lnglat(long, lat)) %>%
  stretch() %>%
  mutate(wk = lubridate::week(date)) %>%
  group_by(wk) %>%
  summarise(prcp = sum(prcp, na.rm = TRUE)) %>%
  tamp()
```

### Hierarchical data structure

Imposing a clustering structure can be thought of as building a hierarchical structure where stations are nested within clusters. As an example to illustrate here, we use a kmean clustering algorithm based on the distance matrix and specify the number of centers to be 20. More complex algorithms can also be used for more complex problem, as long as a mapping from each station id to the cluster id can be constructed. We then join this data to our station data:

```{r}
dist_raw <- scale(s2::s2_distance_matrix(station_nested$ll, station_nested$ll))

cluster_res <- tibble(
  id = station_nested$id,
  cluster = kmeans(dist_raw, centers = 20, nstart = 50)$cluster
)

station_nested <- station_nested %>%
  left_join(cluster_res)
```

One thing we hope to do with the cluster is to find the coordinates of the centroid. These are variables variant to the station but invariant to the cluster and it would be nice to have a function that structure each cluster as a row. `switch_key()` is the function that does this: it lets you to specify a new key, say `cluster` and nests all spatial variables variant to `cluster` into a column. Temporal observations from different stations while within the same cluster are bound in the nested column `ts`.

```{r}
cluster_nested <- station_nested %>%
  switch_key(cluster)
```

This structure makes it easy to compute cluster level variable, although there are a few steps to calculate the centroid coordinates: we need to find the convex hull that wraps around the cluster, make it a polygon, find the centroid of the polygon and finally, extract the x and y coordinate of each centroid:

```{r}
cluster_nested <- cluster_nested %>%
  mutate(
    chull = list(chull(.val$long, .val$lat)),
    ll_cluster = sf::st_as_sfc(
      s2::s2_make_polygon(c(.val$long[chull]),
        c(.val$lat[chull]),
        oriented = FALSE
      )
    ),
    centroid = s2::s2_centroid(ll_cluster),
    cent_long = s2::s2_x(centroid),
    cent_lat = s2::s2_y(centroid)
  )
```

After we have got `cluster_nested`, spatial and temporal data at both levels can be easily obtained. If we use `station` and `cluster` prefix to denote the two levels and `nested` and `long` for whether the data shows the spatial or temporal dimension, the relationship among the four datasets can be illustrated in the following workflow:


Start with the original `station_nested`, `stretch()` expands the `ts` column with each station (`id`) forming a group and attach variables invariant to `id` as an attribute. `switch_key()` changes the `key` from `id` to `cluster` and nests all the spatial variables that variant to `cluster`. `stretch()` `cluster_nested` will store variables that are invariant to `cluster` as a tibble in the attribute.

Now we can obtain the aggregated series as described in the workflow diagram above and construct the glyph map with `GGally::glyphs()`: 

```{r}
cluster_long <- cluster_nested %>%
  stretch(ts) %>%
  group_by(wk) %>%
  summarise(prcp = sum(prcp, na.rm = TRUE)) %>%
  migrate(cent_long, cent_lat)

gly <- GGally::glyphs(cluster_long,
  x_major = "cent_long", x_minor = "wk",
  y_major = "cent_lat", y_minor = "prcp",
  height = 2, width = 4
)

state_map <- rmapshaper::ms_simplify(ozmaps::abs_ste, keep = 2e-3)
plot_map(state_map) +
  geom_text(
    data = cluster_nested,
    aes(x = cent_long, y = cent_lat, label = cluster)
  ) +
  geom_path(
    data = gly,
    aes(x = gx, y = gy, group = gid)
  )
```

We can also look at the precipitation of each individual station within the same cluster: 

```{r fig.height = 5, fig.cap = "shtishisa"}
station_long <- station_nested %>%
  stretch(ts) %>%
  migrate(cluster)
station_long %>%
  ggplot(aes(x = wk, y = prcp, group = id)) +
  geom_line(alpha = .3) +
  facet_wrap(vars(cluster), scales = "free_y", ncol = 4) +
  theme_bw()
```

Lastly, there is one series on Tasmania island standing out from others, lets look at where it is: 

```{r}
# this part still needs some fixing
tas_latlong <- station_nested %>%
  filter(lat < -40) %>%
  mutate(p = max(ts$prcp)) %>%
  strip_rowwise() %>%
  filter(p == max(p))

state_map <- rmapshaper::ms_simplify(ozmaps::abs_ste, keep = 2e-3)
plot_map(state_map) +
  geom_point(data = station_nested, aes(x = long, y = lat), size = 0.5) +
  geom_sf(data = cluster_nested, aes(geometry = ll_cluster), fill = "transparent") +
  geom_point(data = tas_latlong, aes(x = long, y = lat), col = "red")
```

## Matching precipitation and river level in Victria water gauges

The water level data comes from [Bureau of Meteorology](http://www.bom.gov.au/metadata/catalogue/19115/ANZCW0503900528?template=full) and has a copy in `weatherdata`. Here we extract the water course level and add a column annotate this data of type `river`. For the rainfall data, we will still use the `weatherdata::climate_full`, filtering for Victorian stations in 2020 should be pretty familiar by now. Again, we first look at where these stations are on the map first:

```{r}
river <- weatherdata::water %>%
  stretch() %>%
  select(date, Water_course_level) %>%
  tamp() %>%
  mutate(type = "river")

climate <- weatherdata::climate_full %>%
  filter(between(stringr::str_sub(id, 7, 8), 76, 90)) %>%
  stretch() %>%
  filter(lubridate::year(date) == 2020) %>%
  tamp() %>%
  mutate(type = "climate")

vic_map <- rmapshaper::ms_simplify(ozmaps::abs_ste %>% filter(NAME == "Victoria"))
plot_map(vic_map) +
  geom_point(
    data = dplyr::bind_rows(river, climate),
    aes(x = long, y = lat, color = type)
  ) +
  scale_color_brewer(palette = "Dark2") +
  theme_bw()
```

### Theory

Temporal matching checks how spatially matched pairs align temporally. We use the following chart to illustrate how the temporal matching works:

```{r echo = FALSE, fig.height=3, fig.cap = "shtishisaasdf"}
set.seed(123)
dt <- tibble(
  id = factor(c(rep("A", 31), rep("a", 31)), levels = c("A", "a")),
  date = rep(1:31, 2),
  val = c(
    c(rnorm(5), 10, rnorm(7), 5, rnorm(8), 7, rnorm(8)),
    c(
      rnorm(6, sd = 0.5), 7, rnorm(7, sd = 0.5), rnorm(6, sd = 0.5),
      4, rnorm(5, sd = 0.5), 6, rnorm(4, sd = 0.5)
    )
  )
) %>% mutate(val = ifelse(val < 0, 0, val))

circle <- tibble(
  x = c(6, 14, 23, 7, 21, 27),
  y = c(10, 5, 7, 7, 4, 6),
  id = factor(c(rep("A", 3), rep("a", 3)), levels = c("A", "a")),
  xend = x + 5
)

errorbar <- bind_rows(
  circle %>% filter(id == "A"),
  circle %>% filter(id == "A") %>% mutate(id = "a")
) %>%
  mutate(id = factor(id, c("A", "a")))

fallin <- tibble(
  id = factor(rep("a", 2), c("A", "a")),
  x = c(7, 27),
  y = -0.5,
  label = "\U2714"
)

ggplot() +
  geom_line(data = dt, aes(x = date, y = val, group = id), color = "grey60") +
  geom_vline(data = circle, aes(xintercept = x), linetype = "longdash", color = "grey60") +
  geom_errorbar(data = errorbar, aes(xmin = x, xmax = xend, y = -0.5), width = 0.5) +
  geom_point(data = circle, aes(x = x, y = y), color = "brown") +
  geom_text(data = fallin, aes(x = x, y = y, label = label), color = "brown", size = 5) +
  facet_wrap(vars(id), nrow = 2) +
  scale_y_continuous(breaks = seq(0, 10, 2)) +
  scale_x_continuous(breaks = seq(1, 31, 1)) +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  labs(x = "Time", y = "Value")
```

For each spatially matched pair, say `A` and `a`, we first find the largest `n` points in each series, colored in brown points here. Here we use the largest three but you can tune this number by `temporal_n_highest`. Then we construct the interval of the largest points from one series and see how many points, from the other series, fall into the intervals. The series used to construct the interval is controlled by `temporal_independent` and the window size by `temporal_window` with a default of 5. 

In this illustration, we construct the interval based on series `A` and two of the three peaks from `a` falls into this interval at Time 7 and 27. 

### Rainfall translates into river level

There's another mandatory argument that hasn't been introduced above: `temporal_var_to_match`. This argument controls the variable to match and it needs to appear in both the `major` and `minor` set. In the water level matching example, we match the variable `Water_course_level` from `river` to `prcp` from `climate`, hence need to manually rename one of them to match the other, here we rename `Water_course_level` to `prcp` in `river`: 

```{r}
river <- river %>%
  stretch() %>%
  rename(prcp = Water_course_level) %>%
  tamp()
```

Now we use `match_sites()` to first pair the weather stations with the river gauges spatially and then apply the temporal matching on `prcp`. We will construct the interval based on peaks in `climate` since we would expect a lag effect for precipitation to flow into the river and cause a raise in river level, hence `temporal_independent = climate`. We select the 30 highest peak from the series to construct the match by setting `temporal_n_highest = 30`. This is a tuning parameter and you can start with 10% of the points of one series (here we have daily data for a year, 10% is roughly 30 points). `temporal_min_match` filters out pairs don't have enough match and to return all the pairs, set `temporal_min_match` to `0`. 


```{r}
res <- match_sites(river, climate,
  temporal_var_to_match = prcp,
  temporal_independent = climate,  
  temporal_n_highest = 30,
  temporal_min_match = 15
)

res
```

The output from temporal matching is also a cubble, with additional column `.dist` and `.group` inherent from spatial matching and `n_match` for the number of matched temporal peaks. Then you can use this output to plot the location of match or to look at the series: 
```{r out.width="100%", fig.cap="..."}
p1 <- plot_map(vic_map) +
  geom_point(
    data = res,
    aes(x = long, y = lat, color = type)
  ) +
  ggrepel::geom_label_repel(
    data = res %>% filter(type == "river"),
    aes(x = long, y = lat, label = .group)
  ) +
  scale_color_brewer(palette = "Dark2") +
  ggtitle("Victoria") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    legend.position = "bottom"
  )

res_long <- res %>%
  stretch(ts) %>%
  migrate(.group, type) %>%
  mutate(prcp = scale(prcp)[, 1]) %>%
  switch_key(.group) %>%
  migrate(type)

p2 <- res_long %>%
  ggplot(aes(
    x = date, y = prcp,
    group = id, color = type
  )) +
  geom_line() +
  facet_wrap(vars(.group)) +
  scale_color_brewer(palette = "Dark2", guide = "none") +
  theme_bw() +
  labs(x = "week") +
  scale_x_date(date_labels = "%b")

p1 | p2
```

## Interative graphic with cubble 

```{r eval = FALSE}
set.seed(123)
tmax_data <- weatherdata::climate_full %>%
  slice_sample(n = 50) %>%
  stretch() %>%
  mutate(ym = tsibble::yearmonth(date)) %>%
  group_by(ym) %>%
  summarise(
    tmax = mean(tmax, na.rm = TRUE),
    tmin = mean(tmin, na.rm = TRUE),
    prcp = sum(prcp, na.rm = TRUE)
  ) %>%
  ungroup(ym) %>%
  mutate(
    year = as.factor(year(ym)),
    month = as.factor(month(ym)),
    prcp = sqrt(prcp + 0.001)
  ) %>%
  tamp() %>%
  mutate(median_tmax = median(ts$tmax, na.rm = TRUE)) %>%
  stretch() %>%
  migrate(median_tmax, long, lat, name) %>%
  highlight_key(~id)

p1 <- tmax_data %>%
  ggplot(aes(
    x = month, y = tmax, group = interaction(year, id),
    color = median_tmax, label = name
  )) +
  geom_line() +
  facet_wrap(vars(fct_reorder(name, -median_tmax))) +
  theme(legend.position = "none")

state_map <- rmapshaper::ms_simplify(ozmaps::abs_ste, keep = 2e-3)
p2 <- tmax_data %>%
  ggplot() +
  geom_sf(data = state_map, aes(geometry = geometry)) +
  geom_point(aes(x = long, y = lat, color = median_tmax, label = name)) +
  theme_void()

bscols(
  ggplotly(p1, width = 800, height = 800, tooltip = "label") %>%
    highlight(on = "plotly_selected", off = "plotly_deselect", color = "red"),
  ggplotly(p2, width = 800, height = 800, tooltip = "label") %>%
    highlight(on = "plotly_selected", off = "plotly_deselect", color = "red")
)
```


# Conclusion


\newpage

# Old stuff


Many spatial and spatio-temporal data structures have been developed by the R-spatial team for both raster and vector spatial data. For vector spatial data, which is the focus of this paper, `sf` [@pebesma2018simple] represents spatial vector information with simple features: points, lines, polygons and their multiples. Various `st_` function are designed to manipulate these features based on their geometric relationships. For spatio-temporal data,  `stars` [@stars] can represent both raster and vector data using multi-dimensional array. However, the underlying array structure can be difficult to operate for data analysts who are more familiar with a flat 2D data frame structure used by the tidyverse ecosystem.

In the temporal aspect, the `tsibble` [@tsibbles] structure and its tidyverts ecosystem have provided a [... ] workflow to work with temporal data. In a tsibble structure, temporal data is characterised by `index` and `key` where `index` is the temporal identifier and `key` is the identifier for multiple series, which could be used as a spatio identifier. However, a tsibble object, by construction, always requires the `index` in its structure. This makes it less appealing for spatio-temporal data since the output of calculated spatio-specific variables (i.e. features of each series) don't have the time dimension. Analysts will either need to have an additional step to join this output to the original tsibble or operate with variables stored in two separate objects. In addition, the long form structure of a tsibble object means spatio variables (i.e. longitude, latitude, and features of each series if joined back to the tsibble) of each spatio identifier will be repetitively recorded at each timestamp. This repetition is unnecessary and would inflate the object size for long series.

# A new data structure for spatio-temporal data

**The main difficulty and challenge**  
The main difficulty in visualising this type of data is to show information in both space and time dimension with the proper level of details without information overflow. This would sometimes require aggregating the time dimension into the proper level or slicing the data into a reasonable number of subset for display. In this sense, a data structure that regulates the manipulation spatio-temporal data will benefit the analysis workflow. While many implementations focus on manipulating and visualising pure spatial or temporal data, there are not sufficient tools to deal with spatio-temporal data. The purpose of this paper is to introduce a spatio-temporal vector data structure for data analysis in R. 

To work with spatio-temporal data, analysts can choose to either work separately on each dimension or join the two sets together, however, each approach has its own problem: While is is natural to work separately on each sheet (since spatial and temporal operations usually don't overlap), analysts will need to manually keep the other data frame up to date. For example, the following pseudo code illustrates the scenario where once the spatial dataset is filtered for those within Victoria, the temporal dataset needs to be manually updated to reflect this spatial filter.

```{r eval = FALSE}
spatial_new <- spatial %>% filter(SITES_IN_VICTORIA)
temporal_new <- temporal %>% filter(id %in% spatial_new$id)
```

If analysts choose to join the spatial and temporal data together, the joined dataset could be too large since each spatial variable will be repeated at each time stamp for each site. Also, recordings of the site ID from different data sources can be slightly different from each other, causing a painful checking and cleaning of site IDs before the join.


\newpage

# Create a cubble

The creation of a cubble requires the site identifier (`key`), as well as the spatial (`coords`) and temporal (`index`) identifier. `climate_flat` is already a tibble and it uses `id` to identify each station, `date` as the time identifier, and `c(long, lat)` as the spatial identifier. To create a cubble for this data, use:

```{r}
climate_flat %>% as_cubble(key = id, index = date, coords = c(long, lat))
```

Most of the time, spatio-temporal data doesn't come into this form and analysts need to query the climate variables based on station metadata. \textcolor{red}{This is also a problem illustrated in Section 3.5 in @tidydata. Here we provide a structured way to query this data based on the row-wise operator and nested list.} For this type of task, one can structure a metadata into a tibble and use row-wise operator to query the climate variables into a nested list. As an example here we demonstrate the workflow to find the 5 closest stations to Melbourne. We first create a station data frame with the 5 target stations.

```{r echo = FALSE}
latlon_ref <- tibble::tibble(id = "melbourne", lat = -37.8136, long = 144.9631)

cand <- aus_climate %>%
  as_tibble() %>%
  select(id, lat, long, elev, name, wmo_id)


calc_dist <- function(df_ref, df, n = 5) {
  long_ref <- df_ref$long
  lat_ref <- df_ref$lat

  df %>%
    mutate(
      long_ref = long_ref,
      lat_ref = lat_ref,
      dist = rnoaa::meteo_spherical_distance(lat, long, lat_ref, long_ref)
    ) %>%
    slice_min(dist, n = n) %>%
    mutate(city = df_ref$id) %>%
    select(-long_ref, -lat_ref)
}

(stations <- do.call("rbind", purrr::map(
  1:nrow(latlon_ref),
  ~ calc_dist(latlon_ref[.x, ], cand)
)))
```

We can query the climate information into a nested list named `ts` for each station with the `rowwise()` operator. To create a cubble, supply the same identifiers as with the first example.


```{r eval = FALSE}
sydmel_climate <- stations %>%
  rowwise() %>%
  mutate(ts = list(meteo_pull_monitors(id,
    date_min = "2020-01-01",
    date_max = "2020-12-31",
    var = c("PRCP", "TMAX", "TMIN")
  ) %>%
    select(-id))) %>%
  as_cubble(key = id, index = date, coords = c(long, lat))
```

```{r echo = FALSE}
(sydmel_climate <- stations %>%
  left_join(aus_climate) %>%
  as_cubble(key = id, index = date, coords = c(long, lat)))
```


Below are the how the nested and long form look like for Australia climate data, which records daily precipitation, maximum and minimum temperature for 55 stations across Australia from 2015- 2020. Notice that each station forms a group in both forms and specifically, the nested  and long form have a underlying `rowwise_df` and `grouped_df` respectively.


With a cubic framework on mind, different types of manipulation with cubble can be thought of as slicing the cube in various way. The table below shows how some `dplyr` verbs are mapped into the operation in a cubble. With the existing grouping on the station, additional groupping can be added with `group_by` and removed with `ungrouped`. [talk about why it is useful]

\newpage

## Cubble operations

```{r cubble-operations, echo = FALSE, fig.cap="Cubble operations", out.height="50%", out.width="90%", fig.align='center'}
knitr::include_graphics(here::here("figures/cubble-operations/cubble-operations.001.png"))
```

### Basics

- `stretch`: nest to long form
- `tamp`: long to nest form
- `migrate`: move selected spatial variables to the long form.
- `add_dscrb_prct`: summary stats for missingness

dplyr compatibility:

  - mutate, filter, summarise, select, arrange
  - group and ungroup: group_by, ungroup
  - slice family

### Combine two cubbles

  - match river and weather gauges data
  - involve combining two cubbles
  - join operations combine the two together by appending more rows but what we really want is to bind rows.
  - bind rows also doesn't work since we want to bind only when there' s a matching????
  - introduce bind_join

### Hierarchical structure in cubble

  - hierarchical is common.
  - Given examples.
  - Essence: switch between different levels
  - introduce `switch_key`


# Examples

Daily climate data (prcp, tmax, and tmin) from RNOAA - lots of stations across Australia

An exploratory data analysis questions: What's the climate profile look like in Australia

  - General features: Any general trend/ fluctuation in prcp, tmax, and tmin?
  - Local features: Any station stands out from the crowd?
