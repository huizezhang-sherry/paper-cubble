---
documentclass: jss
author:
  - name: H. Sherry Zhang
    # department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    #location: Melbourne, Australia
    email: \email{huize.zhang@monash.edu}
  - name: Dianne Cook
    # department: Department of Econometrics and Business Statistics
    affiliation: 'Monash University \AND'
    # location: Melbourne, Australia
    # email:  dicook@monash.edu
  - name: Ursula Laa
    # department: Institute of Statistics
    affiliation: 'University of Natural Resources and Life Sciences \AND'
    # location: Vienna, Austria
    # email:  ursula.laa@boku.ac.at
  - name: Nicolas Langrené
    # department: 34 Village Street, Docklands VIC 3008 Australia
    affiliation: 'CSIRO Data61 \AND'
    # location: Melbourne, Australia
    # email: nicolas.langrene@csiro.au
  - name: Patricia Menéndez
    # department: Department of Econometrics and Business Statistics
    affiliation: 'Monash University \AND'
    # location: Melbourne, Australia
    # email:  patricia.menendez@monash.edu
title:
  formatted: "\\pkg{cubble}: An R Package for Structuring Spatio-temporal Data"
  # If you use tex in the formatted title, alsoge supply version without
  plain:     "cubble: An R Package for Structuring Spatio-temporal Data"
  # For running headers, if needed
  # short:     "\\pkg{foo}: A Capitalized Title"
abstract: >
  The abstract of the article.
keywords:
  # at least one keyword must be supplied
  formatted: [spatio-temporal data,  "\\proglang{R}"]
  plain:     [spatio-temporal data, R]
preamble: >
  \usepackage{amsmath}
  \usepackage{array}
output: rticles::jss_article
bibliography: references.bib
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  cache = TRUE,
  fig.path = "figures/",
  fig.height = 10
)
options(prompt = "R> ", continue = "+ ", 
        tibble.print_max = 5, tibble.print_min = 5)
```

```{r echo = FALSE}
library(cubble)
library(forcats)
library(stringr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(GGally)
library(plotly)
library(crosstalk)
library(patchwork)
```

\newpage

# Introduction

Many data structures have been proposed for spatial (\pkg{sf} by @sf) and temporal (\pkg{tsibble} by @tsibble) data in the R community, while less has been done for spatio-temporal data. The lack of such tools could potentially because analysts usually treat the spatial and temporal dimension of the data separately, without realising the need to create a new data structure. While this approach follows the third tidy data principal [@tidydata] (*Each type of observational unit forms a table*), analysts always need to manually join results from different observational units or combining multiple tables into one for downstream analysis. This additional step doesn't add new operations into the data but can be error prone. \newline

Currently, available spatio-temporal data structure in R includes: \pkg{spacetime} [@spacetime], which proposes four space-time layouts: Full grid (STF), sparse grid(STS), irregular (STI), and trajectory (STT). The data structure it uses is based on \pkg{sp} [@sp] and \pkg{xts} [@xts], both of which has been replaced by more recent implementations. \pkg{spatstat} [@spatstat] implements a `ppp` class for point pattern data; and more recent, \pkg{stars} [@stars] implements a spatio-temporal array with the dplyr's data cube structure \pkg{cubelyr} [@cubelyr] as its backend. While these implementations either store spatial and temporal variables all in a single table, hence duplicate the spatial variables for each temporal unit; or split them into two separate tables that has the problem of manually joining, mentioned in the previously. None of these packages enjoy both the benefits of being able to separate manipulation in the two dimensions while also keep the data object as a whole. This create a gap in the software development. The requirement for such a tool is important given the ubiquity of spatio-temporal vector data in the wild: the Ireland wind data from \pkg{gstat} is an classic example data that splits variables into spatial (`wind.loc`) and temporal (`wind`) dimension; Bureau of Meteorology (BoM) provides climate observations that are widely applied in agriculture and ecology study; air pollution data. \newline

This paper describes the implementation of a new spatio-temporal data structure: \pkg{cubble}. \pkg{cubble} implements a relational data structure that uses two forms to manage the switch between spatial and temporal dimension. With this structure, users can manipulate the spatial or temporal dimension separately, while leaves the linking of two dimensions to \pkg{cubble}. The software is available from the Comprehensive R Archive Network (CRAN) at [CRAN link]. \newline

The rest of the paper will be divided as follows: [complete when the paper structure is more solid]

<!-- Section 2 reviews the existing data structure for spatio, temporal, and spatio-temporal data. Section 3 presents a new data structure for spatio-temporal data: cubble. Then the paper introduces the workflow of data manipulation and visualisation with the cubble structure in Section 4. Section 5 gives some examples on how common spatial and temporal manipulations are performed with cubble and how static and interactive visualisation help to understand climate and [...] data. \newline -->

\newpage

# The cubble package

Spatio-temporal data usually come in various forms and Figure \ref{fig:illu-input} shows four examples of this. No matter which form the data is in, these formats share some common components that characterise spatio-temporal data. A spatial identifier (`id` in the diagram) is the unique identifier of each site. The temporal identifier (`t` in the diagram) prescribes the time stamp each site is recorded. Coordinates, comprising of latitude and longitude (`lon` and `lat` in the diagram), locates each site on the map. These identifiers will be the building blocks for the data structure introduced below. Other variables in the data can be categorised into two groups: spatial variables that are invariant at each time stamp for every site, i.e. the name or code of the weather station and temporal variables that varies with time.

```{r illu-input, echo = FALSE, out.width = "100%", fig.cap="Illustration of incoming data formats for spatio-temporal data. (1) Data comes in as a single table; (2) Separate tables for spatial and temporal variables; (3) A single table with all the parameters used to query the database and a separate table for queried data; and (4) Cubical data in array or NetCDF format.", fig.align='center', out.height = "15%"}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.001.png"))
```

In a cubble, there are two forms: nested form and long form, and Figure \ref{fig:illu-cubble} sketches the two forms along with the associated attributes. The decision on which form to use is output-oriented, meaning analysts need to first think about whether the output of a particular operation is identified only by the spatial identifier, or a combination of spatial and temporal identifier. The nested cubble is suitable for working with operations that are only identified by site and this type of operation can be a pure manipulation of spatial variables, or a summary of temporal variables by site (i.e. the output of counting the number of raining day is only identified by sites and hence should be performed with the nested form). Underneath the nested form, a cubble is built from a row-wise dataframe (`rowwise_df`) where each site forms a separate group. This structure simplifies the calculation that involves temporal variables by avoiding the use of `map` syntax when working with list-column.

For those operations whose output involves both a spatial and temporal dimension, long form should be used. The long form is identified by both the spatial and temporal identifier and adopts a grouped dataframe (`grouped_df`) to forms each site as a group. Spatial variables are stored separately in a \pkg{tibble} as an special attribute of the long cubble. This design avoids repeating the spatial variables at each time stamp while not dropping information from spatial variables.

```{r illu-cubble, echo = FALSE, fig.align="center", out.width = "100%", fig.cap = "Illustration of nested and long cubble."}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.002.png"))
```

## Create a cubble in the nested form

To use functionalities from cubble, data analysts first need to create a cubble. `as_cubble` create a \pkg{cubble} by supplying the three key components: `key` as the spatial identifier; `index` as the temporal identifier; and a vector of `coords` in the order of longitude first and then latitude. The naming of `key` and `index` follows the convention in the \pkg{tsibble} package. The cubble created by default is in the nested form. Below is an example of creating a cubble: \newline

```{r}
(cubble_nested <- cubble::climate_flat %>%
  as_cubble(key = id, index = date, coords = c("long", "lat")))
```

There are a few information in the \pkg{cubble} header: the name of the `key` variable, bbox, and also the name of variable nested in the `ts` column. In this example, each site is identifier is `id` and the number in the bracket means there are 5 unique `id` in this dataset. The bbox in the second row gives the range of the coordinates. The temporal variables are all nested in the `ts` column, but it could be useful to know the name these variables. The third row in the cubble header shows these names and in this example this includes: precipitation, `prcp`, maximum temperature, `tmax`, and minimum temperature, `tmin`.

## Stretch a nested cubble into the long form

The long cubble is suitable to manipulate the time dimension of the data. The function `stretch()` switches the nested cubble into the long cubble by first extracts all the spatial variables into a separate tibble and store in the `spatial` attribute and then unnests the `ts` column:

```{r}
(cubble_long <- cubble_nested %>% stretch(ts))
```

Notice here that the third line in the header now shows the name of spatial variables rather than the temporal variables.

## Tamp a long cubble back to the nested form

Manipulation on the spatial and temporal dimension can be an iterative process. Many times, analysts will need to go back and forth between the nested and long cubble. The `stretch()` function introduced in the previous section switches a nested cubble into a long cubble and function `tamp()` is its inverse function to switch a long cubble back to the nested cubble:

```{r}
(cubble_back <- cubble_long %>% tamp())
```

## Migrate spatial variables to a long cubble

As a final data output for modelling or visualisation, spatio-temporal data is usually expected to be in a single table. Function `migrate()` moves the spatial variables from the `spatial` attribute into the long cubble:

```{r}
(cubble_long %>% migrate(long, lat))
```

In this workflow described above, data objects come into cubble in the nested form, then various operations on the spatial and temporal dimension can go back and forth between the nested and long form, and finally, the data will come out of cubble in the long form for further modelling or visualisation.

Building from an underlying `tbl_df` structure, it is natural to implement methods available in `dplyr` to `cubble`. Supported methods in the `cubble` with `dplyr` generics includes:

```{=tex}
\begin{center}
\begin{tabular}{ | m{5em} | m{15cm}| } 
basics & \textbf{mutate}, \textbf{filter}, \textbf{summarise}, \textbf{select}, \textbf{arrange}, \textbf{rename}, \textbf{left\_join} \\
grouping &  \textbf{group\_by}, \textbf{ungroup}\\
slice family & \textbf{slice\_head}, \textbf{slice\_tail}, \textbf{slice\_sample}, \textbf{slice\_min} and \textbf{slice\_max} \\
\end{tabular}
\end{center}
```
\pkg{cubble} is also compatible with \pkg{tsibble} in the sense that the original list-column can be a `tbl_ts` object. Duplicates and gaps should be first checked before structuring the data into a cubble. If the input data is a \pkg{tsibble} object, the long form cubble is also a \pkg{tsibble} where users can directly apply time series operations.

# Advanced features/ considerations

## Hierarchical structure


Imposing a clustering structure can be thought of as building a hierarchical structure where stations are nested within clusters. This can be useful when there's intrinsic nesting structure in the data (i.e. country nested in the continent, county nested in the state) or there's some clustering. When we have access to both level, `switch_key()` is the function to re-structure the data as one cluster per row. Temporal observations from different stations while within the same cluster are bound in the nested column `ts`.

One thing we hope to do with the cluster is to find the coordinates of the centroid. These are variables variant to the station but invariant to the cluster and it would be nice to have a function that structure each cluster as a row. `switch_key()` is the function that does this: it lets you to specify a new key, say `cluster` and nests all spatial variables variant to `cluster` into a column. Spatial variables are all nested inside a new column `.val`. Temporal observations from different stations while within the same cluster are bound in the nested column `ts`.

This structure makes it easy to compute cluster level variable, for example, the convex hull and the centroid coordinate of each cluster. These can be amended into the nested form with function `get_centroid`.

After we have got `cluster_nested`, spatial and temporal data at both levels can be easily obtained. Figure \ref{fig:illu-hier} illustrate the relationship between the long and nested form cubble at both site and cluster level. More description on this. Start with the original `station_nested`, `stretch()` expands the `ts` column with each station (`id`) forming a group and attach variables invariant to `id` as an attribute. `switch_key()` changes the `key` from `id` to `cluster` and nests all the spatial variables that variant to `cluster`. `stretch()` `cluster_nested` will store variables that are invariant to `cluster` as a tibble in the attribute.

this fit into the remaining data pipeline. 

```{r illu-hier, echo = FALSE, fig.align="center", out.width = "100%", fig.cap = "Hierarchical structure"}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.003.png"))
```

## Data fusion and matching

Temporal matching checks how spatially matched pairs align temporally. We use the following chart to illustrate how the temporal matching works:

For each spatially matched pair, say `A` and `a`, we first find the largest `n` points in each series, colored in brown points here. Here we use the largest three but you can tune this number by `temporal_n_highest`. Then we construct the interval of the largest points from one series and see how many points, from the other series, fall into the intervals. The series used to construct the interval is controlled by `temporal_independent` and the window size by `temporal_window` with a default of 5.

In this illustration, we construct the interval based on series `A` and two of the three peaks from `a` falls into this interval at Time 7 and 27.

There's another mandatory argument that hasn't been introduced above: `temporal_var_to_match`. This argument controls the variable to match and it needs to appear in both the `major` and `minor` set. In the water level matching example, we match the variable `Water_course_level` from `river` to `prcp` from `climate`, hence need to manually rename one of them to match the other, here we rename `Water_course_level` to `prcp` in `river`:



Figure \ref{fig:illu-matching}

```{r illu-matching, out.width="100%", out.height="30%", fig.cap="sdfasdf"}
knitr::include_graphics("figures/illu-matching.png")
```

## Interactive graphics

<!-- Interactive graphics can listen to users' actions on the plot to provide additional information that facilitates data exploration. This is a useful technique for spatio-temporal data since users can zoom or pan the map to view the local and global structure of the map; use tooltips or popups to query more information about a graphic element; or highlight points to explore its linked views in other plots. In the R community, many implementations have been developed to connect \proglang{R} to \proglang{javascript} to create interactive graphics. In relation to spatio, temporal, and spatio-temporal data, the general purpose packages \pkg{plotly} [@plotly] and \pkg{leaflet} [@leaflet] realise various interactive actions through their corresponding javascript libraries. \pkg{crosstalk} [@crosstalk] and \pkg{tsibbletalk} [@tsibbletalk] implement brushed linking between htmlwidgets. \pkg{ggiraph} [@ggiraph] enables tooltip, self-linking, and customised actions specified through its own \proglang{javascript}. -->

<!-- While many graphic implementations present worked examples to illustrate the usage of the package, few documents the underlying pipeline that transforms the raw data step-by-step to the final view on the screen. There have been some early work in building the data pipeline for (interactive) graphics [@buja1988elements; @buja1996interactive;  @sutherland2000orca] and more recent discussions include @wickham2009plumbing, @xie2014reactive, and @cheng2016enabling. -->

The cubble structure fits in naturally with the interactive graphic pipeline discussed in the literature [@buja1988elements; @buja1996interactive;  @sutherland2000orca; @xie2014reactive; @cheng2016enabling]. Diagram \ref{fig:illu-interactive} illustrates how linking works with the two forms in a cubble, where a time series plot is created with the long cubble and a map is created with the nested cubble. When a user action is captured from the map, the site will be activated in the nested cubble. Then, the nested cubble will communicate to the long cubble to activate all the observations with the same `id`. The long cubble will then highlight the  activated series in the time series plot. 

The linking is also available from the time series plot to the map. The selection on the time series is through selecting the point on the time series and once a point is selected, it will be activated in the long cubble. All the observations that share the same `id`,  either in the long and nested cubble, are then activated. This includes other points in the same time series in the long cubble and the corresponding observation of site in the nested cubble. These activated observations will then being reflected in the updated plots and Diagram \ref{fig:illu-interactive-2} in the Appendix illustrates this process. 

```{r illu-interactive, echo = FALSE, fig.align="center", out.height="40%", out.width = "100%", fig.cap = "demon interactivity"}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.004.png"))
```

\newpage

# Examples

## Australia historical maximum temperature

Global Historical Climatology Network (GHCN) provides daily climate measures from stations across the world and the dataset `weatherdata::historical_tmax` extracts the historical maximum temperature recorded for `r nrow(weatherdata::historical_tmax)` Australian stations. The data `historical_tmax` is already presented as a cubble, with `id` as the key, `date` as the index, and `c("longitude", "latitude")` as the coordinates. Other variables include `elevation`, `name`, `wmo_id`, `first_year`, and  `last_year` in the nested form and `tmax` in the long form. This example compares the maximum temperature in two periods: 1971 - 1975 and 2016 - 2020 for stations in Victoria and New South Wales.

Stations in the two states can be subsetted on the station number: Australia GHCN station number starts with `ASN00` and followed by the [Bureau of Meteorology (BOM) station number](http://www.bom.gov.au/climate/cdo/about/site-num.shtml), where the 2nd and 3rd digit (7th and 8th in the GHCN number) denote the state a station belongs to. New South Wales stations start from 46 to 75 and Victoria stations then follow from 76 to 90. Extracting Victoria and New South Wales stations is a filter operation in the spatial dimension and hence is operated in the nested form: 

```{r eval = FALSE, echo = TRUE}
tmax <- weatherdata::historical_tmax %>%
  filter(between(stringr::str_sub(id, 7, 8), 46, 90))
```

The five year window is chosen to remove the effect of a particular year and the historical period of 1971 - 1975 is used since all the stations have records from 1970. This following chunk filters on records in the two study periods and summarises the maximum temperature into monthly measure. `stretch()` is used to convert the nested form cubble into the long form for these operations:

```{r eval=  FALSE, echo = TRUE}
tmax <- tmax %>% 
  stretch() %>%
  filter(lubridate::year(date) %in% c(1971:1975, 2016:2020)) %>%
  mutate(month = lubridate::month(date), 
         group = as.factor(ifelse(lubridate::year(date) > 2015, 
                                  "2016 ~ 2020", "1971 ~ 1975"))) %>%
  group_by(month, group) %>%
  summarise(tmax = mean(tmax, na.rm = TRUE))
```  

A data quality issue with GHCN data is that while the first and last year of each series is provided, years missing in this period is not reported. There are a few stations which don't have records during 1971 - 1975 and these stations are filtered out by examining whether the summarised `tmax` has a total of 24 months. This is again a station-wise operation and is operated in the nested form, which is switched to from the long form by  `tamp()`:

```{r eval = FALSE, echo = TRUE}
tmax <- tmax %>% 
  tamp() %>%
  filter(nrow(ts) == 24) 
```

Lastly, to create a glyph map, both the major (`longitude`, `latitude`) and minor (`month`, `tmax`) coordinates need to be in the same table. Spatial variables can be moved to the long form with `migrate()`:

```{r eval = FALSE, echo = TRUE}  
tmax <- tmax %>%   
  stretch() %>%
  migrate(latitude, longitude)
```

Figure \ref{fig:basic-manip} shows the glyph map made with the data after the wangling above. One issue with this map is that the similar pattern shown from a few nearby stations around Sydney (151E, 34S) and New castle (152E, 33S) can be distracting. Aggregation is a useful technique to observe the general pattern of a collection of series and will be the topic of the next example.

```{r basic-manip, out.width="100%", out.height="70%", fig.cap="Glyph map of the mean maximum temperature by month for Victoria and New South Wales weather stations. On the top left corner is a detailed legend for station Cobar highlighted in the black box. Compared to 1971 - 1975,  the period 2016 - 2020 sees an increase of mean maximum temperature in spring and summer in Australia (end and beginning of the year). A larger increase during the first three months of the year is observed at stations with a lower latitude."}
knitr::include_graphics("figures/basic-manip.png")
```



## Australia precipitation pattern in 2020


In Figure \ref{fig:basic-agg}. Aggregating them into averages or other statistics would give a better picture. This can be done with cubble through a hierarchical structure, where the cluster indicator is one level above the individual station. 



The `weatherdata::climate_full` data has daily climate data of `r nrow(weatherdata::climate_full)` Australia stations from 2016 to 2020. 

calcluate distance matrix
As an example to illustrate here, a kmean clustering algorithm based on the distance matrix is used and the number of centres is set to 20. More complex algorithms can also be used for more complex problem, as long as a mapping from each station id to the cluster id can be constructed. 


<!-- Now we can obtain the aggregated series as described in the workflow diagram above and construct the glyph map with `GGally::glyphs()`: -->

<!-- We can also look at the precipitation of each individual station within the same cluster: -->


<!-- Lastly, there is one series on Tasmania island standing out from others, lets look at where it is: -->


```{r basic-agg, out.width="100%", out.height="90%", fig.cap="sdfasdf"}
knitr::include_graphics("figures/basic-agg.png")
```


## River level data in Victria water gauges

The water level data comes from [Bureau of Meteorology](http://www.bom.gov.au/metadata/catalogue/19115/ANZCW0503900528?template=full) and has a copy in `weatherdata`. Here we extract the water course level and add a column annotate this data of type `river`. For the rainfall data, we will still use the `weatherdata::climate_full`, filtering for Victorian stations in 2020 should be pretty familiar by now. Again, we first look at where these stations are on the map first:

Now we use `match_sites()` to first pair the weather stations with the river gauges spatially and then apply the temporal matching on `prcp`. We will construct the interval based on peaks in `climate` since we would expect a lag effect for precipitation to flow into the river and cause a raise in river level, hence `temporal_independent = climate`. We select the 30 highest peak from the series to construct the match by setting `temporal_n_highest = 30`. This is a tuning parameter and you can start with 10% of the points of one series (here we have daily data for a year, 10% is roughly 30 points). `temporal_min_match` filters out pairs don't have enough match and to return all the pairs, set `temporal_min_match` to `0`.``

The output from temporal matching is also a cubble, with additional column `.dist` and `.group` inherent from spatial matching and `n_match` for the number of matched temporal peaks. Then you can use this output to plot the location of match or to look at the series:


```{r matching, out.width="100%", out.height="30%", fig.cap="asdfasd"}
knitr::include_graphics("figures/matching.png")
```



## ERA5: climate reanalysis data

\newpage

## Interative graphic with cubble

To visualise climate variables from all the stations in Australia, interactive graphics can be helpful. Here a plotly and a leaflet example is given to explore the yearly diurnal temperature range pattern in Australia. This would be useful to see how the average temperature range differs in various latitudes in Australia, whether there's a summer or winter effect, any coastline, mountain or desert topological considerations that would affect the temperature.

Again, `weatherdata::climate_full` will be first processed to produce summarised monthly maximum and minimum temperature across 2016 to 2020. Then a shared data with the same group is created from the nested and long cubble to enable the cross-talking via the common column `id`. The map and temperature band is created separately with the two shared data objects and combined together with `crosstalk::bscols`. A sketch of the code to produce Figure \ref{fig:interactive-linking} is presented below:

```{r eval = FALSE, echo = TRUE}
# data processing
clean <- weatherdata::climate_full %>% ...

# created grouped instance for crosstalk
nested <- clean %>% SharedData$new(~id, group = "cubble")
long <- stretch(clean) %>% SharedData$new(~id, group = "cubble")

# create the map with SharedData nested, the time series with SharedData long
p1 <- nested %>% ...
p2 <- long %>% ...

# Combine p1 and p2
crosstalk::bscols(plotly::ggplotly(p1), plotly::ggplotly(p2), ...)

```

In Figure \ref{fig:interactive-linking}, the first row shows the default plot and when a selection is made, relevant component from both plots will be highlighted. For example, in the second row, the highest mean maximum temperature in July is selected on the time series and this corresponds to Kalumburu on the map where there is a larger diurnal temperature range in winter (June to August) than summer (December to February). The third row selects a station (Birdsville Airport) in the interior desert region that has a large average temperature difference on the map and the linked view shows a wide but constant diurnal temperature range throughout the year. The last row selects the lowest maximum temperature in July on the right plot and surprisingly, this links to the Thredbo airport at the boarder of Victoria and New South Wales, rather than any station in the Tasmania island! 

```{r interactive-linking, echo = FALSE, out.width="100%", out.height="25%", fig.retina = 2, dpi = 300, fig.cap = "Screenshots of the mean daily temperature difference averaged by month from 2016 to 2020 at various locations in Australia. Crossed linking between the map and the temperature band is implemented in both directions for exploring the temperature pattern interactively. The first row is the general appearance of the graph and the next three rows are examples from various selection to show different temperature patterns in Australia. The html version can be found at ...", fig.show='hold'}
knitr::include_graphics(here::here("figures/linking.png"))
knitr::include_graphics(here::here("figures/linking-north.png"))
knitr::include_graphics(here::here("figures/linking-mid.png"))
knitr::include_graphics(here::here("figures/linking-south.png"))
```

With leaflet popup, the temperature range can be displayed as a small plot upon clicking on the station on the map. This would require first creating all the popup plot separately in a vector and then add these plots to a leaflet map with `leafpop::addPopupGraphs()`:

```{r eval = FALSE, echo = TRUE}
# create subplots for each station
df_id <- unique(clean$id)
p <- map(1:length(df_id), function(i){
  dt <- clean %>% filter(id == df_id[i])
  dt %>% ...
})

# inset subplots as a popup in leaflet
leaflet(clean) %>% 
  addTiles() %>% 
  addCircleMarkers(group = "a", ...) %>% 
  leafpop::addPopupGraphs(graph = p, ...)

```

Figure \ref{fig:interactive-popup} shows more examples of temperature pattern that can be found in Australia. With the same latitude as Kalumburu but in the Pacific coastline, Cooktown airport shows a similarly high but constant temperature range throughout the year. With a slightly higher latitude than the Thredbo airport , Melbourne airport shows a less extreme temperature pattern Lastly, the Cape Grim Baps, in the north-west tip of the Tasmania island shows low and narrow temperature band, constantly betwee 10 and 20 degree throughout the year.

```{r interactive-popup, echo = FALSE, out.width="45%", out.height="30%", fig.retina = 2, dpi = 300, fig.cap = "Screenshots of the diurnal temperature range averaged by month from 2016 to 2020 at various locations in Australia. The leaflet popup allows users to click on a single station for its temperature band as a small plot in the popup window. The html version can be found at ...", fig.show='hold'}
knitr::include_graphics(here::here("figures/popup-north.png"))
knitr::include_graphics(here::here("figures/popup-vic.png"))
knitr::include_graphics(here::here("figures/popup-tas.png"))
```


# Conclusion

# Appendix

```{r illu-interactive-2, echo = FALSE, fig.align="center", out.height="40%", out.width = "100%", fig.cap = "demon interactivity"}
knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.005.png"))
```

\newpage

<!-- # Old stuff -->

<!-- In the temporal aspect, the `tsibble` [@tsibbles] structure and its tidyverts ecosystem have provided a [... ] workflow to work with temporal data. In a tsibble structure, temporal data is characterised by `index` and `key` where `index` is the temporal identifier and `key` is the identifier for multiple series, which could be used as a spatio identifier. However, a tsibble object, by construction, always requires the `index` in its structure. This makes it less appealing for spatio-temporal data since the output of calculated spatio-specific variables (i.e. features of each series) don't have the time dimension. Analysts will either need to have an additional step to join this output to the original tsibble or operate with variables stored in two separate objects. In addition, the long form structure of a tsibble object means spatio variables (i.e. longitude, latitude, and features of each series if joined back to the tsibble) of each spatio identifier will be repetitively recorded at each timestamp. This repetition is unnecessary and would inflate the object size for long series. -->

<!-- # Create a cubble -->

<!-- The creation of a cubble requires the site identifier (`key`), as well as the spatial (`coords`) and temporal (`index`) identifier. `climate_flat` is already a tibble and it uses `id` to identify each station, `date` as the time identifier, and `c(long, lat)` as the spatial identifier. To create a cubble for this data, use: -->

<!-- ```{r} -->
<!-- climate_flat %>% as_cubble(key = id, index = date, coords = c(long, lat)) -->
<!-- ``` -->

<!-- Most of the time, spatio-temporal data doesn't come into this form and analysts need to query the climate variables based on station metadata. \textcolor{red}{This is also a problem illustrated in Section 3.5 in @tidydata. Here we provide a structured way to query this data based on the row-wise operator and nested list.} For this type of task, one can structure a metadata into a tibble and use row-wise operator to query the climate variables into a nested list. As an example here we demonstrate the workflow to find the 5 closest stations to Melbourne. We first create a station data frame with the 5 target stations. -->

<!-- ```{r echo = FALSE} -->
<!-- latlon_ref <- tibble::tibble(id = "melbourne", lat = -37.8136, long = 144.9631) -->

<!-- cand <- aus_climate %>% -->
<!--   as_tibble() %>% -->
<!--   select(id, lat, long, elev, name, wmo_id) -->


<!-- calc_dist <- function(df_ref, df, n = 5) { -->
<!--   long_ref <- df_ref$long -->
<!--   lat_ref <- df_ref$lat -->

<!--   df %>% -->
<!--     mutate( -->
<!--       long_ref = long_ref, -->
<!--       lat_ref = lat_ref, -->
<!--       dist = rnoaa::meteo_spherical_distance(lat, long, lat_ref, long_ref) -->
<!--     ) %>% -->
<!--     slice_min(dist, n = n) %>% -->
<!--     mutate(city = df_ref$id) %>% -->
<!--     select(-long_ref, -lat_ref) -->
<!-- } -->

<!-- (stations <- do.call("rbind", purrr::map( -->
<!--   1:nrow(latlon_ref), -->
<!--   ~ calc_dist(latlon_ref[.x, ], cand) -->
<!-- ))) -->
<!-- ``` -->

<!-- We can query the climate information into a nested list named `ts` for each station with the `rowwise()` operator. To create a cubble, supply the same identifiers as with the first example. -->

<!-- ```{r eval = FALSE} -->
<!-- sydmel_climate <- stations %>% -->
<!--   rowwise() %>% -->
<!--   mutate(ts = list(meteo_pull_monitors(id, -->
<!--     date_min = "2020-01-01", -->
<!--     date_max = "2020-12-31", -->
<!--     var = c("PRCP", "TMAX", "TMIN") -->
<!--   ) %>% -->
<!--     select(-id))) %>% -->
<!--   as_cubble(key = id, index = date, coords = c(long, lat)) -->
<!-- ``` -->

<!-- ```{r echo = FALSE} -->
<!-- (sydmel_climate <- stations %>% -->
<!--   left_join(aus_climate) %>% -->
<!--   as_cubble(key = id, index = date, coords = c(long, lat))) -->
<!-- ``` -->

<!-- Below are the how the nested and long form look like for Australia climate data, which records daily precipitation, maximum and minimum temperature for 55 stations across Australia from 2015- 2020. Notice that each station forms a group in both forms and specifically, the nested and long form have a underlying `rowwise_df` and `grouped_df` respectively. -->

<!-- With a cubic framework on mind, different types of manipulation with cubble can be thought of as slicing the cube in various way. The table below shows how some `dplyr` verbs are mapped into the operation in a cubble. With the existing grouping on the station, additional grouping can be added with `group_by` and removed with `ungrouped`. [talk about why it is useful] -->

<!-- \newpage -->

<!-- ## Cubble operations -->

<!-- ```{r cubble-operations, echo = FALSE, fig.cap="Cubble operations", out.height="50%", out.width="90%", fig.align='center'} -->
<!-- knitr::include_graphics(here::here("figures/diagram-keynotes/diagram-keynotes.004.png")) -->
<!-- ``` -->
