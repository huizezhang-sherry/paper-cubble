\documentclass[
]{jss}

\usepackage[utf8]{inputenc}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\author{
H. Sherry Zhang\\Monash University \And Dianne Cook\\Monash University
\AND Ursula Laa\\University of Natural Resources and Life Sciences
\AND Nicolas Langrené\\CSIRO Data61 \AND Patricia
Menéndez\\Monash University \AND
}
\title{\pkg{cubble}: An R Package for Structuring Spatio-temporal Data}

\Plainauthor{H. Sherry Zhang, Dianne Cook, Ursula Laa, Nicolas
Langrené, Patricia Menéndez}
\Plaintitle{cubble: An R Package for Structuring Spatio-temporal Data}

\Abstract{
The abstract of the article.
}

\Keywords{spatio-temporal data, \proglang{R}}
\Plainkeywords{spatio-temporal data, R}

%% publication information
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{}
%% \Acceptdate{2012-06-04}

\Address{
          }

% Pandoc citation processing

% Pandoc header

\usepackage{amsmath} \usepackage{array}

\begin{document}

\newpage

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Many data structures have been proposed for spatial (\pkg{sf} by
\citet{sf}) and temporal (\pkg{tsibble} by \citet{tsibble}) data in the
R community, while less has been done for spatio-temporal data. The lack
of such tools could potentially because analysts usually treat the
spatial and temporal dimension of the data separately, without realising
the need to create a new data structure. While this approach follows the
third tidy data principal \citep{tidydata} (\emph{Each type of
observational unit forms a table}), analysts always need to manually
join results from different observational units or combining multiple
tables into one for downstream analysis. This additional step doesn't
add new operations into the data but can be error prone. \newline

Currently, available spatio-temporal data structure in R includes:
\pkg{spacetime} \citep{spacetime}, which proposes four space-time
layouts: Full grid (STF), sparse grid(STS), irregular (STI), and
trajectory (STT). The data structure it uses is based on \pkg{sp}
\citep{sp} and \pkg{xts} \citep{xts}, both of which has been replaced by
more recent implementations. \pkg{spatstat} \citep{spatstat} implements
a \texttt{ppp} class for point pattern data; and more recent,
\pkg{stars} \citep{stars} implements a spatio-temporal array with the
dplyr's data cube structure \pkg{cubelyr} \citep{cubelyr} as its
backend. While these implementations either store spatial and temporal
variables all in a single table, hence duplicate the spatial variables
for each temporal unit; or split them into two separate tables that has
the problem of manually joining, mentioned in the previously. None of
these packages enjoy both the benefits of being able to separate
manipulation in the two dimensions while also keep the data object as a
whole. This create a gap in the software development. The requirement
for such a tool is important given the ubiquity of spatio-temporal
vector data in the wild: the Ireland wind data from \pkg{gstat} is an
classic example data that splits variables into spatial
(\texttt{wind.loc}) and temporal (\texttt{wind}) dimension; Bureau of
Meteorology (BoM) provides climate observations that are widely applied
in agriculture and ecology study; air pollution data. \newline

This paper describes the implementation of a new spatio-temporal data
structure: \pkg{cubble}. \pkg{cubble} implements a relational data
structure that uses two forms to manage the switch between spatial and
temporal dimension. With this structure, users can manipulate the
spatial or temporal dimension separately, while leaves the linking of
two dimensions to \pkg{cubble}. The software is available from the
Comprehensive R Archive Network (CRAN) at {[}CRAN link{]}. \newline

The rest of the paper will be divided as follows: {[}complete when the
paper structure is more solid{]}

\newpage

\hypertarget{the-cubble-package}{%
\section{The cubble package}\label{the-cubble-package}}

Spatio-temporal data usually come in various forms and Figure
\ref{fig:illu-input} shows four examples of this. No matter which form
the data is in, these formats share some common components that
characterise spatio-temporal data. A spatial identifier (\texttt{id} in
the diagram) is the unique identifier of each site. The temporal
identifier (\texttt{t} in the diagram) prescribes the time stamp each
site is recorded. Coordinates, comprising of latitude and longitude
(\texttt{lon} and \texttt{lat} in the diagram), locates each site on the
map. These identifiers will be the building blocks for the data
structure introduced below. Other variables in the data can be
categorised into two groups: spatial variables that are invariant at
each time stamp for every site, i.e.~the name or code of the weather
station and temporal variables that varies with time.

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth,height=0.15\textheight]{/Users/sherryzhang/Documents/research/paper-cubble/figures/diagram-keynotes/diagram-keynotes.001} 

}

\caption[Illustration of incoming data formats for spatio-temporal data]{Illustration of incoming data formats for spatio-temporal data. (1) Data comes in as a single table; (2) Separate tables for spatial and temporal variables; (3) A single table with all the parameters used to query the database and a separate table for queried data; and (4) Cubical data in array or NetCDF format.}\label{fig:illu-input}
\end{figure}
\end{CodeChunk}

In a cubble, there are two forms: nested form and long form, and Figure
\ref{fig:illu-cubble} sketches the two forms along with the associated
attributes. The decision on which form to use is output-oriented,
meaning analysts need to first think about whether the output of a
particular operation is identified only by the spatial identifier, or a
combination of spatial and temporal identifier. The nested cubble is
suitable for working with operations that are only identified by site
and this type of operation can be a pure manipulation of spatial
variables, or a summary of temporal variables by site (i.e.~the output
of counting the number of raining day is only identified by sites and
hence should be performed with the nested form). Underneath the nested
form, a cubble is built from a row-wise dataframe (\texttt{rowwise\_df})
where each site forms a separate group. This structure simplifies the
calculation that involves temporal variables by avoiding the use of
\texttt{map} syntax when working with list-column.

For those operations whose output involves both a spatial and temporal
dimension, long form should be used. The long form is identified by both
the spatial and temporal identifier and adopts a grouped dataframe
(\texttt{grouped\_df}) to forms each site as a group. Spatial variables
are stored separately in a \pkg{tibble} as an special attribute of the
long cubble. This design avoids repeating the spatial variables at each
time stamp while not dropping information from spatial variables.

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{/Users/sherryzhang/Documents/research/paper-cubble/figures/diagram-keynotes/diagram-keynotes.002} 

}

\caption[Illustration of nested and long cubble]{Illustration of nested and long cubble.}\label{fig:illu-cubble}
\end{figure}
\end{CodeChunk}

\hypertarget{create-a-cubble-in-the-nested-form}{%
\subsection{Create a cubble in the nested
form}\label{create-a-cubble-in-the-nested-form}}

To use functionalities from cubble, data analysts first need to create a
cubble. \texttt{as\_cubble} create a \pkg{cubble} by supplying the three
key components: \texttt{key} as the spatial identifier; \texttt{index}
as the temporal identifier; and a vector of \texttt{coords} in the order
of longitude first and then latitude. The naming of \texttt{key} and
\texttt{index} follows the convention in the \pkg{tsibble} package. The
cubble created by default is in the nested form. Below is an example of
creating a cubble: \newline

\begin{CodeChunk}
\begin{CodeOutput}
# cubble:   id [5]: nested form
# bbox:     [115.97, -32.94, 133.55, -12.42]- check gap on long and lat
# temporal: date [date], prcp [dbl], tmax [dbl], tmin [dbl]
  id            lat  long  elev name           wmo_id ts                
  <chr>       <dbl> <dbl> <dbl> <chr>           <dbl> <list>            
1 ASN00009021 -31.9  116.  15.4 perth airport   94610 <tibble [366 x 4]>
2 ASN00010311 -31.9  117. 179   york            94623 <tibble [366 x 4]>
3 ASN00010614 -32.9  117. 338   narrogin        94627 <tibble [366 x 4]>
4 ASN00014015 -12.4  131.  30.4 darwin airport  94120 <tibble [366 x 4]>
5 ASN00015131 -17.6  134. 220   elliott         94236 <tibble [366 x 4]>
\end{CodeOutput}
\end{CodeChunk}

There are a few information in the \pkg{cubble} header: the name of the
\texttt{key} variable, bbox, and also the name of variable nested in the
\texttt{ts} column. In this example, each site is identifier is
\texttt{id} and the number in the bracket means there are 5 unique
\texttt{id} in this dataset. The bbox in the second row gives the range
of the coordinates. The temporal variables are all nested in the
\texttt{ts} column, but it could be useful to know the name these
variables. The third row in the cubble header shows these names and in
this example this includes: precipitation, \texttt{prcp}, maximum
temperature, \texttt{tmax}, and minimum temperature, \texttt{tmin}.

\hypertarget{stretch-a-nested-cubble-into-the-long-form}{%
\subsection{Stretch a nested cubble into the long
form}\label{stretch-a-nested-cubble-into-the-long-form}}

The long cubble is suitable to manipulate the time dimension of the
data. The function \texttt{stretch()} switches the nested cubble into
the long cubble by first extracts all the spatial variables into a
separate tibble and store in the \texttt{spatial} attribute and then
unnests the \texttt{ts} column:

\begin{CodeChunk}
\begin{CodeOutput}
# cubble:  date, id [5]: long form
# bbox:    [115.97, -32.94, 133.55, -12.42]- check gap on long and lat
# spatial: lat [dbl], long [dbl], elev [dbl], name [chr], wmo_id [dbl]
  id          date        prcp  tmax  tmin
  <chr>       <date>     <dbl> <dbl> <dbl>
1 ASN00009021 2020-01-01     0  31.9  15.3
2 ASN00009021 2020-01-02     0  24.9  16.4
3 ASN00009021 2020-01-03     6  23.2  13  
4 ASN00009021 2020-01-04     0  28.4  12.4
5 ASN00009021 2020-01-05     0  35.3  11.6
# ... with 1,825 more rows
\end{CodeOutput}
\end{CodeChunk}

Notice here that the third line in the header now shows the name of
spatial variables rather than the temporal variables.

\hypertarget{tamp-a-long-cubble-back-to-the-nested-form}{%
\subsection{Tamp a long cubble back to the nested
form}\label{tamp-a-long-cubble-back-to-the-nested-form}}

Manipulation on the spatial and temporal dimension can be an iterative
process. Many times, analysts will need to go back and forth between the
nested and long cubble. The \texttt{stretch()} function introduced in
the previous section switches a nested cubble into a long cubble and
function \texttt{tamp()} is its inverse function to switch a long cubble
back to the nested cubble:

\begin{CodeChunk}
\begin{CodeOutput}
# cubble:   id [5]: nested form
# bbox:     [115.97, -32.94, 133.55, -12.42]- check gap on long and lat
# temporal: date [date], prcp [dbl], tmax [dbl], tmin [dbl]
  id            lat  long  elev name           wmo_id ts                
  <chr>       <dbl> <dbl> <dbl> <chr>           <dbl> <list>            
1 ASN00009021 -31.9  116.  15.4 perth airport   94610 <tibble [366 x 4]>
2 ASN00010311 -31.9  117. 179   york            94623 <tibble [366 x 4]>
3 ASN00010614 -32.9  117. 338   narrogin        94627 <tibble [366 x 4]>
4 ASN00014015 -12.4  131.  30.4 darwin airport  94120 <tibble [366 x 4]>
5 ASN00015131 -17.6  134. 220   elliott         94236 <tibble [366 x 4]>
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{migrate-spatial-variables-to-a-long-cubble}{%
\subsection{Migrate spatial variables to a long
cubble}\label{migrate-spatial-variables-to-a-long-cubble}}

As a final data output for modelling or visualisation, spatio-temporal
data is usually expected to be in a single table. Function
\texttt{migrate()} moves the spatial variables from the \texttt{spatial}
attribute into the long cubble:

\begin{CodeChunk}
\begin{CodeOutput}
# cubble:  date, id [5]: long form
# bbox:    [115.97, -32.94, 133.55, -12.42]- check gap on long and lat
# spatial: lat [dbl], long [dbl], elev [dbl], name [chr], wmo_id [dbl]
  id          date        prcp  tmax  tmin  long   lat
  <chr>       <date>     <dbl> <dbl> <dbl> <dbl> <dbl>
1 ASN00009021 2020-01-01     0  31.9  15.3  116. -31.9
2 ASN00009021 2020-01-02     0  24.9  16.4  116. -31.9
3 ASN00009021 2020-01-03     6  23.2  13    116. -31.9
4 ASN00009021 2020-01-04     0  28.4  12.4  116. -31.9
5 ASN00009021 2020-01-05     0  35.3  11.6  116. -31.9
# ... with 1,825 more rows
\end{CodeOutput}
\end{CodeChunk}

In this workflow described above, data objects come into cubble in the
nested form, then various operations on the spatial and temporal
dimension can go back and forth between the nested and long form, and
finally, the data will come out of cubble in the long form for further
modelling or visualisation.

Building from an underlying \texttt{tbl\_df} structure, it is natural to
implement methods available in \texttt{dplyr} to \texttt{cubble}.
Supported methods in the \texttt{cubble} with \texttt{dplyr} generics
includes:

\begin{center}
\begin{tabular}{ | m{5em} | m{15cm}| } 
basics & \textbf{mutate}, \textbf{filter}, \textbf{summarise}, \textbf{select}, \textbf{arrange}, \textbf{rename}, \textbf{left\_join} \\
grouping &  \textbf{group\_by}, \textbf{ungroup}\\
slice family & \textbf{slice\_head}, \textbf{slice\_tail}, \textbf{slice\_sample}, \textbf{slice\_min} and \textbf{slice\_max} \\
\end{tabular}
\end{center}

\pkg{cubble} is also compatible with \pkg{tsibble} in the sense that the
original list-column can be a \texttt{tbl\_ts} object. Duplicates and
gaps should be first checked before structuring the data into a cubble.
If the input data is a \pkg{tsibble} object, the long form cubble is
also a \pkg{tsibble} where users can directly apply time series
operations.

\newpage

\hypertarget{advanced-features-considerations}{%
\section{Advanced features/
considerations}\label{advanced-features-considerations}}

\hypertarget{hierarchical-structure}{%
\subsection{Hierarchical structure}\label{hierarchical-structure}}

Spatial locations can have further grouping structure either in nature
(i.e.~countries are nested in continents), or calculated by some
clustering algorithms. Rather than investigate the read from individual
locations, group character summarised from multiple locations can give a
clearer picture of the local dynamic. In cubble, \texttt{switch\_key()}
can be used to create a new level of grouping of spatial location by
specifying a clustering variable. Figure \ref{fig:illu-hier} illustrates
the relationship of cubbles at site and cluster level, in both the long
and nested form. By specifying
\texttt{cluster\_nested\ \textless{}-\ station\_nested\ \%\textgreater{}\%\ switch\_key(key\ =\ cluster)},
the cubble re-defines the cubble key from \texttt{id} in
\texttt{station\_nested} to \texttt{cluster} in
\texttt{cluster\_nested}. All the spatial variables variant to
\texttt{cluster} are now nested into a \texttt{.val} column and cluster
level variables can be computed in the same fashion as station level
variables in \texttt{station\_nested}. Following the same principal of
\texttt{stretch}, the long form cluster level cubble expands the time
series variables with both indices: \texttt{cluster} and \texttt{id}.
All the cluster level variables are stored separately for recovering the
nested from from the long form.

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{/Users/sherryzhang/Documents/research/paper-cubble/figures/diagram-keynotes/diagram-keynotes.003} 

}

\caption[Relationship between the station and cluster level cubble in both long and nested form]{Relationship between the station and cluster level cubble in both long and nested form.}\label{fig:illu-hier}
\end{figure}
\end{CodeChunk}

\hypertarget{data-fusion-and-matching}{%
\subsection{Data fusion and matching}\label{data-fusion-and-matching}}

Temporal matching checks how spatially matched pairs align temporally.
We use the following chart to illustrate how the temporal matching
works:

For each spatially matched pair, say \texttt{A} and \texttt{a}, we first
find the largest \texttt{n} points in each series, colored in brown
points here. Here we use the largest three but you can tune this number
by \texttt{temporal\_n\_highest}. Then we construct the interval of the
largest points from one series and see how many points, from the other
series, fall into the intervals. The series used to construct the
interval is controlled by \texttt{temporal\_independent} and the window
size by \texttt{temporal\_window} with a default of 5.

In this illustration, we construct the interval based on series
\texttt{A} and two of the three peaks from \texttt{a} falls into this
interval at Time 7 and 27.

There's another mandatory argument that hasn't been introduced above:
\texttt{temporal\_var\_to\_match}. This argument controls the variable
to match and it needs to appear in both the \texttt{major} and
\texttt{minor} set. In the water level matching example, we match the
variable \texttt{Water\_course\_level} from \texttt{river} to
\texttt{prcp} from \texttt{climate}, hence need to manually rename one
of them to match the other, here we rename \texttt{Water\_course\_level}
to \texttt{prcp} in \texttt{river}:

Figure \ref{fig:illu-matching}

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth,height=0.3\textheight]{figures/illu-matching} 

}

\caption[sdfasdf]{sdfasdf}\label{fig:illu-matching}
\end{figure}
\end{CodeChunk}

\hypertarget{interactive-graphics}{%
\subsection{Interactive graphics}\label{interactive-graphics}}

The cubble structure fits in naturally with the interactive graphic
pipeline discussed in the literature
\citep{buja1988elements, buja1996interactive, sutherland2000orca, xie2014reactive, cheng2016enabling}.
Diagram \ref{fig:illu-interactive} illustrates how linking works with
the two forms in a cubble, where a time series plot is created with the
long cubble and a map is created with the nested cubble. When a user
action is captured from the map, the site will be activated in the
nested cubble. Then, the nested cubble will communicate to the long
cubble to activate all the observations with the same \texttt{id}. The
long cubble will then highlight the activated series in the time series
plot.

The linking is also available from the time series plot to the map. The
selection on the time series is through selecting the point on the time
series and once a point is selected, it will be activated in the long
cubble. All the observations that share the same \texttt{id}, either in
the long and nested cubble, are then activated. This includes other
points in the same time series in the long cubble and the corresponding
observation of site in the nested cubble. These activated observations
will then being reflected in the updated plots and Diagram
\ref{fig:illu-interactive-2} in the Appendix illustrates this process.

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth,height=0.4\textheight]{/Users/sherryzhang/Documents/research/paper-cubble/figures/diagram-keynotes/diagram-keynotes.004} 

}

\caption[demon interactivity]{demon interactivity}\label{fig:illu-interactive}
\end{figure}
\end{CodeChunk}

\hypertarget{glyph-map}{%
\subsection{Glyph map}\label{glyph-map}}

Glyph map \citep{Wickham2012-yr} plots the time series as single glyph
on the map. In \proglang{R}, \texttt{GGally} implements the glyph map
through the \texttt{glyphs()} function, which outputs a data frame with
calculated position (\texttt{gx}, \texttt{gy}, \texttt{gid}) of each
point on the time series given the major and minor xy variable using
linear algebra (Equation 1 and 2 in \citet{Wickham2012-yr}). The data
can then be piped into \texttt{ggplot} to create the glyph map:

\begin{CodeChunk}
\begin{CodeInput}
R> library(ggplot2)
R> gly <- glyphs(data, 
+               x_major = ..., x_minor = ..., 
+               y_major = ..., y_minor = ..., ...)
R> 
R> ggplot(gly, aes(gx, gy, group = gid)) + 
+   geom_path() 
\end{CodeInput}
\end{CodeChunk}

While this calculation can be seen as part of the \texttt{setup\_data()}
in a \texttt{ggproto}. A re-implementation of the glyph map as
\texttt{GeomGlyph} has been made in \texttt{cubble} to create the glyph
map with \texttt{geom\_glyph}:

\begin{CodeChunk}
\begin{CodeInput}
R> ggplot(data = data) +
+   geom_glyph(aes(x_major = ..., x_minor = ..., 
+                  y_major = ..., y_minor = ...))
\end{CodeInput}
\end{CodeChunk}

Polar glyph map can be specify as a parameter, \texttt{polar\ =\ TRUE},
in the \texttt{geom\_glyph()}, along with \texttt{width} and
\texttt{height} in either absolute or relative value. Global and local
scale can also be controlled by the parameter \texttt{global\_rescale},
which default to \texttt{TRUE}. Reference box and line can be added with
separate \texttt{geom\_glyph\_box()} and \texttt{geom\_glyph\_line()}.

\newpage

\hypertarget{examples}{%
\section{Examples}\label{examples}}

\hypertarget{australia-historical-maximum-temperature}{%
\subsection{Australia historical maximum
temperature}\label{australia-historical-maximum-temperature}}

Global Historical Climatology Network (GHCN) provides daily climate
measures from stations across the world and the dataset
\texttt{weatherdata::historical\_tmax} extracts the historical maximum
temperature recorded for 236 Australian stations. The data
\texttt{historical\_tmax} is already presented as a cubble, with
\texttt{id} as the key, \texttt{date} as the index, and
\texttt{c("longitude",\ "latitude")} as the coordinates. Other variables
include \texttt{elevation}, \texttt{name}, \texttt{wmo\_id},
\texttt{first\_year}, and \texttt{last\_year} in the nested form and
\texttt{tmax} in the long form. This example compares the maximum
temperature in two periods: 1971 - 1975 and 2016 - 2020 for stations in
Victoria and New South Wales.

Stations in the two states can be subsetted on the station number:
Australia GHCN station number starts with \texttt{ASN00} and followed by
the \href{http://www.bom.gov.au/climate/cdo/about/site-num.shtml}{Bureau
of Meteorology (BOM) station number}, where the 2nd and 3rd digit (7th
and 8th in the GHCN number) denote the state a station belongs to. New
South Wales stations start from 46 to 75 and Victoria stations then
follow from 76 to 90. Extracting Victoria and New South Wales stations
is a filter operation in the spatial dimension and hence is operated in
the nested form:

\begin{CodeChunk}
\begin{CodeInput}
R> tmax <- weatherdata::historical_tmax %>%
+   filter(between(stringr::str_sub(id, 7, 8), 46, 90))
\end{CodeInput}
\end{CodeChunk}

The five year window is chosen to remove the effect of a particular year
and the historical period of 1971 - 1975 is used since all the stations
have records from 1970. This following chunk filters on records in the
two study periods and summarises the maximum temperature into monthly
measure. \texttt{stretch()} is used to convert the nested form cubble
into the long form for these operations:

\begin{CodeChunk}
\begin{CodeInput}
R> tmax <- tmax %>% 
+   stretch() %>%
+   filter(lubridate::year(date) %in% c(1971:1975, 2016:2020)) %>%
+   mutate(month = lubridate::month(date), 
+          group = as.factor(ifelse(lubridate::year(date) > 2015, 
+                                   "2016 ~ 2020", "1971 ~ 1975"))) %>%
+   group_by(month, group) %>%
+   summarise(tmax = mean(tmax, na.rm = TRUE))
\end{CodeInput}
\end{CodeChunk}

A data quality issue with GHCN data is that while the first and last
year of each series is provided, years missing in this period is not
reported. There are a few stations which don't have records during 1971
- 1975 and these stations are filtered out by examining whether the
summarised \texttt{tmax} has a total of 24 months. This is again a
station-wise operation and is operated in the nested form, which is
switched to from the long form by \texttt{tamp()}:

\begin{CodeChunk}
\begin{CodeInput}
R> tmax <- tmax %>% 
+   tamp() %>%
+   filter(nrow(ts) == 24) 
\end{CodeInput}
\end{CodeChunk}

Lastly, to create a glyph map, both the major (\texttt{longitude},
\texttt{latitude}) and minor (\texttt{month}, \texttt{tmax}) coordinates
need to be in the same table. Spatial variables can be moved to the long
form with \texttt{migrate()}:

\begin{CodeChunk}
\begin{CodeInput}
R> tmax <- tmax %>%   
+   stretch() %>%
+   migrate(latitude, longitude)
\end{CodeInput}
\end{CodeChunk}

Figure \ref{fig:basic-manip} shows the glyph map made with the data
after the wangling above. One issue with this map is that the similar
pattern shown from a few nearby stations around Sydney (151E, 34S) and
New castle (152E, 33S) can be distracting. Aggregation is a useful
technique to observe the general pattern of a collection of series and
will be the topic of the next example.

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth,height=0.7\textheight]{figures/basic-manip} 

}

\caption[Glyph map of the mean maximum temperature by month for Victoria and New South Wales weather stations]{Glyph map of the mean maximum temperature by month for Victoria and New South Wales weather stations. On the top left corner is a detailed legend for station Cobar highlighted in the black box. Compared to 1971 - 1975,  the period 2016 - 2020 sees an increase of mean maximum temperature in spring and summer in Australia (end and beginning of the year). A larger increase during the first three months of the year is observed at stations with a lower latitude.}\label{fig:basic-manip}
\end{figure}
\end{CodeChunk}

\hypertarget{australia-precipitation-pattern-in-2020}{%
\subsection{Australia precipitation pattern in
2020}\label{australia-precipitation-pattern-in-2020}}

With recent climate, there are 639 stations in Australia that records
daily maximum and minimum temperature and precipitation. While it would
be too much series to show on a glyph map, stations close to each other
should have similar precipitation pattern. Aggregation can be helpful
here to cluster series into groups and visualise them with glyph map.

A simple kmean algorithm is used based on the distance matrix to cluster
the stations into 20 groups. This creates \texttt{station\_nested} as a
station level nested cubble with a cluster column indicating which group
each station belongs to. More complex algorithms can be used for more
complex problem, as long as a mapping from each station id to the
cluster id can be constructed.

\begin{CodeChunk}
\begin{CodeOutput}
# cubble:   id [639]: nested form
# bbox:     [113.53, -43.66, 153.64, -10.05]
# temporal: date [date], prcp [dbl], tmax [dbl], tmin [dbl]
  id            lat  long  elev name             wmo_id ts               cluster
  <chr>       <dbl> <dbl> <dbl> <chr>             <dbl> <list>             <int>
1 ASN00001006 -15.5  128.   3.8 wyndham aero      95214 <tibble [1,827 ~       3
2 ASN00001007 -13.8  126.   6   troughton island  94102 <tibble [1,827 ~       3
3 ASN00001018 -16.4  126. 546   mount elizabeth   94211 <tibble [1,460 ~      16
4 ASN00001019 -14.3  127.  23   kalumburu         94100 <tibble [1,827 ~       3
5 ASN00001020 -14.1  126.  51   truscott          95101 <tibble [1,827 ~       3
# ... with 634 more rows
\end{CodeOutput}
\end{CodeChunk}

To create a group level cubble, use \texttt{switch\_key()} with the new
key variable, \texttt{cluster}:

\begin{CodeChunk}
\begin{CodeInput}
R> cluster_nested <- station_nested %>% switch_key(cluster) 
\end{CodeInput}
\end{CodeChunk}

With the group level cubble, it is useful to compute the centroid of
each cluster as the location of group level glyph map.
\texttt{get\_centroid()} is a shortcut for doing so or you can manually
find the convex hull, its centroid, and extract the longitude and
latitude:

\begin{CodeChunk}
\begin{CodeInput}
R> cluster_nested <- cluster_nested %>% 
+   get_centroid()
\end{CodeInput}
\end{CodeChunk}

Long form cubble at both levels can be access through stretching the
nested form. Here weekly averages of the precipitation is calculated:

\begin{CodeChunk}
\begin{CodeInput}
R> station_long <- station_nested %>% 
+   stretch(ts) %>% 
+   mutate(wk = lubridate::week(date)) %>% 
+   group_by(wk) %>% 
+   summarise(prcp = sum(prcp, na.rm = TRUE))
R> 
R> cluster_long <- cluster_nested %>% 
+   stretch(ts) %>% 
+   mutate(wk = lubridate::week(date)) %>% 
+   group_by(wk) %>% 
+   summarise(prcp = mean(prcp, na.rm = TRUE)) %>% 
+   migrate(cent_long, cent_lat)
\end{CodeInput}
\end{CodeChunk}

With the four cubbles: \texttt{station\_nested}, \texttt{station\_long},
\texttt{cluster\_nested}, and \texttt{cluster\_long}, all the
information at both levels are accessible. This allows us to make glyph
map on the cluster level, looking at station composition of each
cluster, and plot the individual series to check for consistency within
groups. Figure \ref{fig:basic-agg} composes of the three plots together
to show the precipitation in Australia.

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/basic-agg} 

}

\caption[Aggregated precipitation in Australia]{Aggregated precipitation in Australia.}\label{fig:basic-agg}
\end{figure}
\end{CodeChunk}

\hypertarget{river-level-data-in-victria-water-gauges}{%
\subsection{River level data in Victria water
gauges}\label{river-level-data-in-victria-water-gauges}}

The water level data comes from
\href{http://www.bom.gov.au/metadata/catalogue/19115/ANZCW0503900528?template=full}{Bureau
of Meteorology} and has a copy in \texttt{weatherdata}. Here we extract
the water course level and add a column annotate this data of type
\texttt{river}. For the rainfall data, we will still use the
\texttt{weatherdata::climate\_full}, filtering for Victorian stations in
2020 should be pretty familiar by now. Again, we first look at where
these stations are on the map first:

Now we use \texttt{match\_sites()} to first pair the weather stations
with the river gauges spatially and then apply the temporal matching on
\texttt{prcp}. We will construct the interval based on peaks in
\texttt{climate} since we would expect a lag effect for precipitation to
flow into the river and cause a raise in river level, hence
\texttt{temporal\_independent\ =\ climate}. We select the 30 highest
peak from the series to construct the match by setting
\texttt{temporal\_n\_highest\ =\ 30}. This is a tuning parameter and you
can start with 10\% of the points of one series (here we have daily data
for a year, 10\% is roughly 30 points). \texttt{temporal\_min\_match}
filters out pairs don't have enough match and to return all the pairs,
set \texttt{temporal\_min\_match} to \texttt{0}.``

The output from temporal matching is also a cubble, with additional
column \texttt{.dist} and \texttt{.group} inherent from spatial matching
and \texttt{n\_match} for the number of matched temporal peaks. Then you
can use this output to plot the location of match or to look at the
series:

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth,height=0.3\textheight]{figures/matching} 

}

\caption[asdfasd]{asdfasd}\label{fig:matching}
\end{figure}
\end{CodeChunk}

\hypertarget{era5-climate-reanalysis-data}{%
\subsection{ERA5: climate reanalysis
data}\label{era5-climate-reanalysis-data}}

\newpage

\hypertarget{interative-graphic-with-cubble}{%
\subsection{Interative graphic with
cubble}\label{interative-graphic-with-cubble}}

With spatio-temporal data, users may wish to make plots to learn the
spatial distribution of a variable or to find patterns such as trend or
seasonality in the time series. Combining this two types of plot with
interactivity let users to link between points on the map and their
corresponding time series and explore the spatial and temporal dimension
of the data simultaneously. Below is an example that describes the
process of building an interactive graphic with \texttt{cubble} and
\texttt{crosstalk}.

Starting with the original data, some pre-processing may be required to
summarise the data before the visualisation. This example explores the
variation of monthly temperature range across 639 weather stations in
Australia and with \texttt{weatherdata::climate\_full}, daily
temperature range is first calculated as the difference between
\texttt{tmax} and \texttt{tmin}. The three daily variables are then
averaged into month over 2016 - 2020 in the long form. Variance of the
temperature difference is then calculated for each station in the nested
form. Then, a \texttt{SharedData} object is constructed for each form of
the cubble and the same \texttt{group} argument ensures the
cross-linking of the two forms via the common \texttt{id} column. The
spatial map and time series plot are then made with each
\texttt{SharedData} objects separately. In this example, stations on the
Australia map, made from the nested form, are coloured by the calculated
variance and a ribbon band is constructed using the long form cubble to
show the maximum and minimum temperature of each station across month.
With a different dataset, users are free to calculate any per station
measure in the nested form or to make any time-wise summary of the data
in the long form to customise the spatial or temporal view. And the
cross-linking is always safeguarded by the shared \texttt{id} column
embedded in the cubble structure. Below is the pseudo code that outlines
the process to construct an interactive graphic described above:

\begin{CodeChunk}
\begin{CodeInput}
R> # data pre-processing
R> clean <- weatherdata::climate_full %>% ...
R> 
R> # created SharedData instance for crosstalk
R> nested <- clean %>% SharedData$new(~id, group = "cubble")
R> long <- stretch(clean) %>% SharedData$new(~id, group = "cubble")
R> 
R> # create the spatial and temporal view each with a ShareData instance
R> p1 <- nested %>% ...
R> p2 <- long %>% ...
R> 
R> # Combine p1 and p2
R> crosstalk::bscols(plotly::ggplotly(p1), plotly::ggplotly(p2), ...)
\end{CodeInput}
\end{CodeChunk}

In Figure \ref{fig:interactive-linking}, the first row shows the initial
view of the interactive graphic. Overall, most regions in Australia have
low variance of temperature range across different months while the
north-west coastline, bottom of South Australia, and Victoria stands out
with larger monthly changes. In the second row, Mount Elizabeth is
selected on the map given its dark colour and this links to the ribbon
on the right where there is a larger temperature range is presented in
Australian winter (June to August). The third row selects the Grampian
station in Victoria and the linked ribbon shows an opposite wider range
in Australian summer period (December to February). The last row selects
point with the lowest minimum temperature in August in the ribbon plot
and surprisingly, this links to the Thredbo Airport in the Victoria and
New South Wales border, rather than somewhere in the Tasmania island!

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth,height=0.2\textheight]{/Users/sherryzhang/Documents/research/paper-cubble/figures/linking} \includegraphics[width=1\linewidth,height=0.2\textheight]{/Users/sherryzhang/Documents/research/paper-cubble/figures/linking-north} \includegraphics[width=1\linewidth,height=0.2\textheight]{/Users/sherryzhang/Documents/research/paper-cubble/figures/linking-mid} \includegraphics[width=1\linewidth,height=0.2\textheight]{/Users/sherryzhang/Documents/research/paper-cubble/figures/linking-south} 

}

\caption[Exploring temperature variation using linkning of a map and seasonal display]{Exploring temperature variation using linkning of a map and seasonal display. Each row is a screen dump of the process. The top row shows all locations and all temperature profiels. Selecting a location with high variance on the map produces the plot in the second row. The maximum nad minimum temperature is shown using a ribbon.}\label{fig:interactive-linking}
\end{figure}
\end{CodeChunk}

With leaflet popup, the temperature range can be displayed as a small
subplot upon clicking on the map. This would require first creating the
popup plots from the long form cubble as a vector and then add these
plots to a leaflet map, created from the nested cubble, with
\texttt{leafpop::addPopupGraphs()}:

\begin{CodeChunk}
\begin{CodeInput}
R> # data pre-processing
R> clean <- weatherdata::climate_full %>% ...
R> 
R> # use the long form to create subplots for each station
R> df_id <- unique(clean$id)
R> p <- map(1:length(df_id), function(i){
+   dt <- clean %>% filter(id == df_id[i])
+   ggplot(dt) %>% ...
+ })
R> 
R> # create nested form leaflet map with temperature band as subplots 
R> nested <- tamp(clean)
R> leaflet(nested) %>% 
+   addTiles() %>% 
+   addCircleMarkers(group = "a", ...) %>% 
+   leafpop::addPopupGraphs(graph = p, ...)
\end{CodeInput}
\end{CodeChunk}

Figure \ref{fig:interactive-popup} shows the same content as Figure
\ref{fig:interactive-linking} but made with leaflet and popups.

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=0.45\linewidth,height=0.25\textheight]{/Users/sherryzhang/Documents/research/paper-cubble/figures/popup-mid} 

}

\caption[Screenshots of variance of monthly temperature range from 2016 to 2020 in Australia]{Screenshots of variance of monthly temperature range from 2016 to 2020 in Australia. Upon clicking a single station on the leaftlet up, the temperature band will be shown as a subplot in the popup box.}\label{fig:interactive-popup}
\end{figure}
\end{CodeChunk}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=1\linewidth,height=0.4\textheight]{/Users/sherryzhang/Documents/research/paper-cubble/figures/diagram-keynotes/diagram-keynotes.005} 

}

\caption[demon interactivity]{demon interactivity}\label{fig:illu-interactive-2}
\end{figure}
\end{CodeChunk}

\bibliography{references.bib}


\end{document}
